# cian_parser_final.py
import time
import re
import json
import sys
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup

class CianParser:
    def __init__(self):
        """–ü–∞—Ä—Å–µ—Ä –¶–ò–ê–ù –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã cian_offers"""
        self.driver = None
        self.conn = None
        self.cursor = None
        self.table_name = "cian_offers"
    
    def setup_browser(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –±—Ä–∞—É–∑–µ—Ä–∞"""
        print("\nüåê –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –±—Ä–∞—É–∑–µ—Ä–∞...")
        
        options = Options()
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
        
        try:
            self.driver = webdriver.Chrome(options=options)
            print("‚úÖ –ë—Ä–∞—É–∑–µ—Ä –∑–∞–ø—É—â–µ–Ω")
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –±—Ä–∞—É–∑–µ—Ä–∞: {e}")
            return False
    
    def setup_database(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ"""
        print("\nüîå –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö...")
        
        db_config = {
            'host': 'localhost',
            'port': '5432',
            'database': 'cian_parser_2',
            'user': 'postgres',
            'password': 'Mamba123'
        }
        
        try:
            import psycopg2
            
            conn = psycopg2.connect(
                host=db_config['host'],
                port=db_config['port'],
                database=db_config['database'],
                user=db_config['user'],
                password=db_config['password'],
                client_encoding='UTF8'
            )
            
            self.conn = conn
            self.cursor = self.conn.cursor()
            
            print(f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ –±–∞–∑–µ: {db_config['database']}")
            print(f"üìã –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–∞–±–ª–∏—Ü—É: {self.table_name}")
            
            self.check_table_structure()
            
            return True
            
        except ImportError:
            print("‚ùå –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install psycopg2-binary")
            return False
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {str(e)}")
            return False
    
    def check_table_structure(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–∞–±–ª–∏—Ü—ã"""
        try:
            self.cursor.execute(f"""
                SELECT EXISTS (
                    SELECT FROM information_schema.tables 
                    WHERE table_name = '{self.table_name}'
                )
            """)
            
            table_exists = self.cursor.fetchone()[0]
            
            if not table_exists:
                print(f"‚ùå –¢–∞–±–ª–∏—Ü–∞ '{self.table_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
                return False
            
            self.cursor.execute(f"""
                SELECT column_name, data_type, is_nullable
                FROM information_schema.columns
                WHERE table_name = '{self.table_name}'
                ORDER BY ordinal_position
            """)
            
            columns = self.cursor.fetchall()
            print(f"\nüìã –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã '{self.table_name}':")
            for col in columns:
                print(f"  {col[0]}: {col[1]}")
            
            required_columns = ['cian_id', 'url', 'price', 'title', 'area_total']
            actual_columns = [col[0] for col in columns]
            
            missing = [col for col in required_columns if col not in actual_columns]
            if missing:
                print(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Å—Ç–æ–ª–±—Ü—ã: {missing}")
                return False
            
            print("‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã –ø–æ–¥—Ö–æ–¥–∏—Ç")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã: {e}")
            return False
    
    def parse_search_page(self, url):
        """–ü–∞—Ä—Å–∏–Ω–≥ –ø–æ–∏—Å–∫–æ–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        print(f"\nüîç –ü–æ–∏—Å–∫ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {url}")
        
        try:
            self.driver.get(url)
            time.sleep(3)
            
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)
            
            links = self.driver.find_elements(By.TAG_NAME, 'a')
            offers = []
            
            for link in links:
                try:
                    href = link.get_attribute('href')
                    if href and 'cian.ru/sale/flat' in href:
                        match = re.search(r'/(\d+)/?$', href)
                        if match:
                            offer_id = match.group(1)
                            if not any(o['id'] == offer_id for o in offers):
                                offers.append({
                                    'id': offer_id,
                                    'url': href
                                })
                except:
                    continue
            
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {len(offers)}")
            return offers[:10]
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {e}")
            return []
    
    def parse_offer(self, offer):
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è"""
        try:
            print(f"\nüìÑ –ü–∞—Ä—Å–∏–º ID: {offer['id']}")
            
            self.driver.get(offer['url'])
            time.sleep(2)
            
            # –°–æ–∑–¥–∞–µ–º BeautifulSoup –æ–±—ä–µ–∫—Ç –¥–ª—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞
            soup = BeautifulSoup(self.driver.page_source, 'html.parser')
            
            data = {
                'cian_id': offer['id'],
                'url': offer['url'],
                'title': self.get_element_text('h1') or self.get_element_text('[data-name="OfferTitle"]'),
                'address': self.get_element_text('[data-name="GeoLabel"]') or self.get_element_text('[data-name="AddressContainer"]'),
                'price': self.extract_price(),
                'price_per_m2': self.extract_price_per_m2(),
                'old_price': self.extract_old_price(),
                'area_total': self.extract_area_from_title() or self.extract_area_from_description(),
                'area_living': self.extract_living_area(),
                'area_kitchen': self.extract_kitchen_area(),
                'floor_current': self.extract_current_floor(),
                'floor_total': self.extract_total_floors(),
                'rooms': self.extract_rooms(),
                'year_built': self.extract_year_built_improved(soup),
                'building_type': self.extract_building_type_improved(soup),
                'property_category': self.extract_property_category_improved(soup),
                'property_type': self.extract_property_type(),
                'description': None,
                'seller_type': self.extract_seller_type(),
                'publication_date': datetime.now().strftime('%Y-%m-%d'),
                'is_active': True,
                'district': self.extract_district(),
                'metro_station': self.extract_metro_station_improved(soup),  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥
                'metro_time': self.extract_metro_time_improved(soup),
                'last_checked': datetime.now()
            }
            
            # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if data['title']:
                print(f"   üìù {data['title'][:50]}...")
            if data['price']:
                print(f"   üí∞ {data['price']:,} ‚ÇΩ")
            if data['address']:
                print(f"   üìç {data['address'][:40]}...")
            if data['building_type']:
                print(f"   üè† –¢–∏–ø –¥–æ–º–∞: {data['building_type']}")
            if data['property_category']:
                print(f"   üè¢ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {data['property_category']}")
            if data['year_built']:
                print(f"   üìÖ –ì–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏: {data['year_built']}")
            if data['metro_station']:
                metro_info = f"üöá –ú–µ—Ç—Ä–æ: {data['metro_station']}"
                if data['metro_time']:
                    metro_info += f" ({data['metro_time']})"
                print(f"   {metro_info}")
            else:
                print(f"   üöá –ú–µ—Ç—Ä–æ: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ (–≤—Ä–µ–º—è: {data['metro_time'] if data['metro_time'] else '–Ω–µ—Ç'})")
            if data['floor_current']:
                print(f"   üè¢ –≠—Ç–∞–∂: {data['floor_current']}/{data['floor_total'] if data['floor_total'] else '?'}")
            
            return data
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            import traceback
            traceback.print_exc()
            return None


    
    def get_element_text(self, selector):
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç —ç–ª–µ–º–µ–Ω—Ç–∞"""
        try:
            element = self.driver.find_element(By.CSS_SELECTOR, selector)
            return element.text.strip()
        except:
            return None
    
    def extract_price(self):
        """–ò–∑–≤–ª–µ—á—å —Ü–µ–Ω—É"""
        try:
            # –û—Å–Ω–æ–≤–Ω–∞—è —Ü–µ–Ω–∞
            price_selectors = [
                '[data-mark="MainPrice"]',
                '[data-name="PriceInfo"] span',
                'span[class*="price"]',
                'div[class*="price"]'
            ]
            
            for selector in price_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for elem in elements:
                        text = elem.text
                        # –£–±–∏—Ä–∞–µ–º –≤–∞–ª—é—Ç—É –∏ –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
                        price_text = re.sub(r'[^\d\s]', '', text)
                        numbers = re.findall(r'[\d\s]+', price_text)
                        if numbers:
                            price_str = numbers[0].replace(' ', '').replace('\xa0', '')
                            if price_str.isdigit() and len(price_str) > 3:
                                return int(price_str)
                except:
                    continue
            
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥
            page_text = self.driver.page_source
            match = re.search(r'"price":\s*(\d+)', page_text)
            if match:
                return int(match.group(1))
                
        except:
            pass
        return None
    
    def extract_old_price(self):
        """–ò–∑–≤–ª–µ—á—å —Å—Ç–∞—Ä—É—é —Ü–µ–Ω—É"""
        try:
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-mark="OldPrice"]')
            for elem in elements:
                text = elem.text
                numbers = re.findall(r'[\d\s]+', text)
                if numbers:
                    price_str = numbers[0].replace(' ', '').replace('\xa0', '')
                    if price_str.isdigit() and len(price_str) > 3:
                        return int(price_str)
        except:
            pass
        return None
    
    def extract_price_per_m2(self):
        """–ò–∑–≤–ª–µ—á—å —Ü–µ–Ω—É –∑–∞ –º2"""
        try:
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-mark="PricePerMeter"]')
            for elem in elements:
                text = elem.text
                numbers = re.findall(r'[\d\s]+', text)
                if numbers:
                    price_str = numbers[0].replace(' ', '').replace('\xa0', '')
                    if price_str.isdigit():
                        return int(price_str)
        except:
            pass
        return None
    
    def extract_area_from_title(self):
        """–ò–∑–≤–ª–µ—á—å –ø–ª–æ—â–∞–¥—å –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
        try:
            title = self.get_element_text('h1') or ''
            match = re.search(r'(\d+[,.]?\d*)\s*–º¬≤', title)
            if match:
                return float(match.group(1).replace(',', '.'))
        except:
            pass
        return None
    
    def extract_area_from_description(self):
        """–ò–∑–≤–ª–µ—á—å –ø–ª–æ—â–∞–¥—å –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è"""
        try:
            # –ò—â–µ–º –≤ –±–ª–æ–∫–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-name="Features"]')
            for elem in elements:
                text = elem.text
                match = re.search(r'(\d+[,.]?\d*)\s*–º¬≤', text)
                if match:
                    return float(match.group(1).replace(',', '.'))
            
            # –ò—â–µ–º –≤ –æ–±—â–µ–º —Ç–µ–∫—Å—Ç–µ
            page_text = self.driver.page_source
            match = re.search(r'"totalArea":\s*(\d+\.?\d*)', page_text)
            if match:
                return float(match.group(1))
        except:
            pass
        return None
    
    def extract_living_area(self):
        """–ò–∑–≤–ª–µ—á—å –∂–∏–ª—É—é –ø–ª–æ—â–∞–¥—å"""
        try:
            # –ò—â–µ–º –≤ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞—Ö
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-name="Features"]')
            for elem in elements:
                text = elem.text
                match = re.search(r'–ñ–∏–ª–∞—è –ø–ª–æ—â–∞–¥—å[:\s]*(\d+[,.]?\d*)\s*–º¬≤', text, re.IGNORECASE)
                if match:
                    return float(match.group(1).replace(',', '.'))
            
            page_text = self.driver.page_source
            match = re.search(r'"livingArea":\s*(\d+\.?\d*)', page_text)
            if match:
                return float(match.group(1))
        except:
            pass
        return None
    
    def extract_kitchen_area(self):
        """–ò–∑–≤–ª–µ—á—å –ø–ª–æ—â–∞–¥—å –∫—É—Ö–Ω–∏"""
        try:
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-name="Features"]')
            for elem in elements:
                text = elem.text
                match = re.search(r'–ü–ª–æ—â–∞–¥—å –∫—É—Ö–Ω–∏[:\s]*(\d+[,.]?\d*)\s*–º¬≤', text, re.IGNORECASE)
                if match:
                    return float(match.group(1).replace(',', '.'))
            
            page_text = self.driver.page_source
            match = re.search(r'"kitchenArea":\s*(\d+\.?\d*)', page_text)
            if match:
                return float(match.group(1))
        except:
            pass
        return None
    
    def extract_rooms(self):
        """–ò–∑–≤–ª–µ—á—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç"""
        try:
            title = self.get_element_text('h1') or ''
            title_lower = title.lower()
            
            if '—Å—Ç—É–¥–∏—è' in title_lower or '–∞–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç' in title_lower:
                return 0
            
            match = re.search(r'(\d+)[-\s]*(?:–∫–æ–º–Ω|–∫–æ–º–Ω–∞—Ç)', title_lower)
            if match:
                return int(match.group(1))
            
            if '1-–∫–æ–º–Ω' in title_lower or '1 –∫–æ–º–Ω' in title_lower:
                return 1
            elif '2-–∫–æ–º–Ω' in title_lower or '2 –∫–æ–º–Ω' in title_lower:
                return 2
            elif '3-–∫–æ–º–Ω' in title_lower or '3 –∫–æ–º–Ω' in title_lower:
                return 3
            elif '4-–∫–æ–º–Ω' in title_lower or '4 –∫–æ–º–Ω' in title_lower:
                return 4
        except:
            pass
        return None
    
    def extract_current_floor(self):
        """–ò–∑–≤–ª–µ—á—å —Ç–µ–∫—É—â–∏–π —ç—Ç–∞–∂"""
        try:
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-name="Features"]')
            for elem in elements:
                text = elem.text
                match = re.search(r'(\d+)\s*—ç—Ç–∞–∂', text)
                if match:
                    return int(match.group(1))
                
                match = re.search(r'(\d+)\s*/\s*(\d+)', text)
                if match and '—ç—Ç–∞–∂' in text.lower():
                    return int(match.group(1))
            
            page_text = self.driver.page_source
            match = re.search(r'"floor":\s*"(\d+)"', page_text)
            if match:
                return int(match.group(1))
            
            match = re.search(r'"floorNumber":\s*(\d+)', page_text)
            if match:
                return int(match.group(1))
                
        except:
            pass
        return None
    
    def extract_total_floors(self):
        """–ò–∑–≤–ª–µ—á—å –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç—Ç–∞–∂–µ–π"""
        try:
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-name="Features"]')
            for elem in elements:
                text = elem.text
                match = re.search(r'–∏–∑\s*(\d+)', text)
                if match:
                    return int(match.group(1))
                
                match = re.search(r'(\d+)\s*/\s*(\d+)', text)
                if match and '—ç—Ç–∞–∂' in text.lower():
                    return int(match.group(2))
            
            page_text = self.driver.page_source
            match = re.search(r'"floorsCount":\s*(\d+)', page_text)
            if match:
                return int(match.group(1))
            
            match = re.search(r'"totalFloors":\s*(\d+)', page_text)
            if match:
                return int(match.group(1))
                
        except:
            pass
        return None
    
    def extract_year_built_improved(self, soup):
        """–ò–∑–≤–ª–µ—á—å –≥–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏ - –£–õ–£–ß–®–ï–ù–ù–´–ô –ú–ï–¢–û–î"""
        try:
            # 1. –ü–æ–∏—Å–∫ –≤ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞—Ö (—Å–∞–º—ã–π –Ω–∞–¥–µ–∂–Ω—ã–π —Å–ø–æ—Å–æ–±)
            page_text = soup.get_text()
            
            # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –≥–æ–¥–∞
            patterns = [
                r'–ì–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏[:\s]*(\d{4})',
                r'–ü–æ—Å—Ç—Ä–æ–µ–Ω –≤[:\s]*(\d{4})',
                r'–°–¥–∞–Ω –≤[:\s]*(\d{4})',
                r'–î–æ–º\s+(\d{4})\s+–≥–æ–¥–∞',
                r'(\d{4})\s+–≥–æ–¥\s+–ø–æ—Å—Ç—Ä–æ–π–∫–∏',
                r'–≥–æ–¥[:\s]*(\d{4})',
                r'built.*?(\d{4})',
                r'construction.*?(\d{4})',
            ]
            
            for pattern in patterns:
                match = re.search(pattern, page_text, re.IGNORECASE)
                if match:
                    year = int(match.group(1))
                    if 1800 <= year <= datetime.now().year:
                        return year
            
            # 2. –ü–æ–∏—Å–∫ –≤ JSON-LD –¥–∞–Ω–Ω—ã—Ö
            json_ld = soup.find('script', type='application/ld+json')
            if json_ld and json_ld.string:
                try:
                    data = json.loads(json_ld.string)
                    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø–æ–ª—è
                    for field in ['yearBuilt', 'dateBuilt', 'constructionDate', 'buildDate']:
                        if field in data:
                            year_str = str(data[field])
                            match = re.search(r'(\d{4})', year_str)
                            if match:
                                year = int(match.group(1))
                                if 1800 <= year <= datetime.now().year:
                                    return year
                except:
                    pass
            
            # 3. –ü–æ–∏—Å–∫ –≤ —Å–∫—Ä–∏–ø—Ç–∞—Ö —Å –¥–∞–Ω–Ω—ã–º–∏
            scripts = soup.find_all('script')
            for script in scripts:
                if script.string:
                    # –ò—â–µ–º –≥–æ–¥ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
                    script_patterns = [
                        r'"year":\s*"(\d{4})"',
                        r'"year":\s*(\d{4})',
                        r'"buildYear":\s*"(\d{4})"',
                        r'"buildYear":\s*(\d{4})',
                        r'"constructionYear":\s*"(\d{4})"',
                        r'"constructionYear":\s*(\d{4})',
                        r'"yearBuilt":\s*"(\d{4})"',
                        r'"yearBuilt":\s*(\d{4})',
                    ]
                    
                    for pattern in script_patterns:
                        match = re.search(pattern, script.string)
                        if match:
                            year = int(match.group(1))
                            if 1800 <= year <= datetime.now().year:
                                return year
            
            # 4. –ü–æ–∏—Å–∫ –ø–æ —Å–µ—Ä–∏–∏ –¥–æ–º–∞ (–∫–æ—Å–≤–µ–Ω–Ω—ã–π —Å–ø–æ—Å–æ–±)
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –¥–æ–º–∞ –∏ –ø—Ä–∏–º–µ—Ä–Ω—ã–π –≥–æ–¥ –ø–æ —Å–µ—Ä–∏–∏
            building_type = self.extract_building_type_improved(soup)
            if building_type:
                # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–µ –≥–æ–¥—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥–æ–º–æ–≤ –≤ –°–ü–±
                if building_type == '—Ö—Ä—É—â–µ–≤—Å–∫–∏–π':
                    return 1960  # –ü—Ä–∏–º–µ—Ä–Ω–æ 1950-1970
                elif building_type == '–±—Ä–µ–∂–Ω–µ–≤—Å–∫–∏–π':
                    return 1975  # –ü—Ä–∏–º–µ—Ä–Ω–æ 1960-1980
                elif building_type == '—Å—Ç–∞–ª–∏–Ω—Å–∫–∏–π':
                    return 1950  # –ü—Ä–∏–º–µ—Ä–Ω–æ 1930-1955
                elif building_type == '–ø–∞–Ω–µ–ª—å–Ω—ã–π':
                    # –î–ª—è –ø–∞–Ω–µ–ª—å–Ω—ã—Ö –¥–æ–º–æ–≤ –≤ –ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–æ–º —Ä–∞–π–æ–Ω–µ
                    if '–≥—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π' in page_text.lower() or '–∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫' in page_text.lower():
                        return 1970  # –¢–∏–ø–∏—á–Ω—ã–µ –≥–æ–¥—ã –¥–ª—è —ç—Ç–æ–≥–æ —Ä–∞–π–æ–Ω–∞
            
            # 5. –ü–æ–∏—Å–∫ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏
            description = soup.find('div', {'data-name': 'Description'})
            if description:
                desc_text = description.get_text()
                match = re.search(r'(\d{4})\s+–≥–æ–¥', desc_text)
                if match:
                    year = int(match.group(1))
                    if 1800 <= year <= datetime.now().year:
                        return year
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –≥–æ–¥–∞ –ø–æ—Å—Ç—Ä–æ–π–∫–∏: {e}")
        return None
    
    def extract_building_type_improved(self, soup):
        """–ò–∑–≤–ª–µ—á—å —Ç–∏–ø –¥–æ–º–∞ - –°–£–ü–ï–† –£–õ–£–ß–®–ï–ù–ù–´–ô –ú–ï–¢–û–î"""
        try:
            page_text = soup.get_text()
            page_text_lower = page_text.lower()
            
            # 1. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–µ—Ä–∏–∏ –¥–æ–º–æ–≤ - —ç—Ç–æ —Å–∞–º—ã–π –Ω–∞–¥–µ–∂–Ω—ã–π —Å–ø–æ—Å–æ–±
            series_patterns = {
                '–ø–∞–Ω–µ–ª—å–Ω—ã–π': [
                    r'—Å–µ—Ä–∏—è\s*[:\s]*(–ü|–ü-|–ü–ê|–ü–ê–ù–ï–õ–¨|–ü–ê–ù)',
                    r'(–ü-?\d+)',  # –ü-44, –ü-3, –ü-55, –ü-46, –ü-30, –ü-43
                    r'(1-?[–õ–ì]-?606)', r'(1-?511)', r'(1-?515)', r'(1-?528)',
                    r'(–ò-?209–ê)', r'(–ò-?155)', r'(–ò-?1723)',
                    r'(–ö-?7)', r'(–ö–¢)',  # –ö–æ—Ç—Ç–µ–¥–∂–Ω—ã–µ —Å–µ—Ä–∏–∏
                    r'(464)', r'(467)', r'(600.11)',
                    r'(–õ–û–î)', r'(–î–û–ö)',  # –õ–µ–Ω–∏–Ω–≥—Ä–∞–¥—Å–∫–∏–µ
                    r'(–ì–û–°)', r'(–î–û–ö)',  # –ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ
                    r'(–ú–û–ü)', r'(–û–ü)',  # –ú–æ—Å–∫–æ–≤—Å–∫–∏–µ
                    r'(—Ö—Ä—É—â–µ–≤–∫|—Ö—Ä—É—â)',  # –•—Ä—É—â–µ–≤–∫–∏ (–æ–±—ã—á–Ω–æ –ø–∞–Ω–µ–ª—å–Ω—ã–µ)
                    r'1–õ–ì-?606', r'1-?–õ–ì-?606',  # –ö–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è —Å–µ—Ä–∏—è –¥–ª—è –ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–æ–≥–æ
                ],
                '–∫–∏—Ä–ø–∏—á–Ω—ã–π': [
                    r'—Å–µ—Ä–∏—è\s*[:\s]*(–ö|–ö–ò–†–ü|–ö–ò–†–ü–ò–ß|–ö–ò–†)',
                    r'(–ö-?\d+)',
                    r'(1-?510)', r'(1-?335)', r'(1-?447)',
                    r'(–¢–∏—à–∏–Ω—Å–∫)', r'(–°–º–∏—Ä–Ω–æ–≤—Å–∫)', r'(–°—Ç–∞–ª–∏–Ω—Å–∫)',  # –°—Ç–∞–ª–∏–Ω–∫–∏ –æ–±—ã—á–Ω–æ –∫–∏—Ä–ø–∏—á–Ω—ã–µ
                    r'(–¶–∞—Ä—Å–∫–æ—Å–µ–ª—å—Å–∫)',
                ],
                '–º–æ–Ω–æ–ª–∏—Ç–Ω—ã–π': [
                    r'—Å–µ—Ä–∏—è\s*[:\s]*(–ú|–ú–û–ù–û–õ–ò–¢|–ú–û–ù)',
                    r'(–ú-?\d+)',
                    r'(–ò-?155)', r'(–ò-?1723)',  # –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –ò-—Å–µ—Ä–∏–∏
                    r'(–ü-?44–¢)', r'(–ü-?3–ú)',  # –ú–æ–¥–µ—Ä–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞–Ω–µ–ª—å–Ω—ã–µ
                    r'(–∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω)',  # –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã
                ],
                '–±–ª–æ—á–Ω—ã–π': [
                    r'—Å–µ—Ä–∏—è\s*[:\s]*(–ë|–ë–õ–û–ö|–ë–õ)',
                    r'(–ë-?\d+)',
                    r'(1-?480)', r'(1-?600)', r'(1-?606)',
                    r'(–õ–µ–Ω–ó–ù–ò–ò–≠–ü)', r'(–°–ü–±)',  # –õ–µ–Ω–∏–Ω–≥—Ä–∞–¥—Å–∫–∏–µ –±–ª–æ–∫–∏
                ],
                '—Ö—Ä—É—â–µ–≤—Å–∫–∏–π': [
                    r'—Ö—Ä—É—â–µ–≤–∫', r'—Ö—Ä—É—â', r'—Ö—Ä—É—â—ë–≤',
                    r'1-?511', r'1-?515', r'–ö-?7',
                ],
                '—Å—Ç–∞–ª–∏–Ω—Å–∫–∏–π': [
                    r'—Å—Ç–∞–ª–∏–Ω–∫', r'—Å—Ç–∞–ª–∏–Ω', r'—Å—Ç–∞–ª–∏–Ω—Å–∫',
                ],
                '–±—Ä–µ–∂–Ω–µ–≤—Å–∫–∏–π': [
                    r'–±—Ä–µ–∂–Ω–µ–≤–∫', r'–±—Ä–µ–∂–Ω–µ–≤', r'–±—Ä–µ–∂–Ω–µ–≤—Å–∫',
                ]
            }
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–µ—Ä–∏–∏ (—Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–π –ø–æ–∏—Å–∫)
            for building_type, patterns in series_patterns.items():
                for pattern in patterns:
                    if re.search(pattern, page_text, re.IGNORECASE):
                        return building_type
            
            # 2. –ò—â–µ–º –ø—Ä—è–º—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –≤ —Ç–µ–∫—Å—Ç–µ
            direct_keywords = {
                '–ø–∞–Ω–µ–ª—å–Ω—ã–π': ['–ø–∞–Ω–µ–ª—å–Ω—ã–π', '–ø–∞–Ω–µ–ª—å–Ω', '–ø–∞–Ω–µ–ª—å'],
                '–∫–∏—Ä–ø–∏—á–Ω—ã–π': ['–∫–∏—Ä–ø–∏—á–Ω—ã–π', '–∫–∏—Ä–ø–∏—á–Ω', '–∫–∏—Ä–ø–∏—á'],
                '–º–æ–Ω–æ–ª–∏—Ç–Ω—ã–π': ['–º–æ–Ω–æ–ª–∏—Ç–Ω—ã–π', '–º–æ–Ω–æ–ª–∏—Ç–Ω', '–º–æ–Ω–æ–ª–∏—Ç'],
                '–±–ª–æ—á–Ω—ã–π': ['–±–ª–æ—á–Ω—ã–π', '–±–ª–æ—á–Ω', '–±–ª–æ–∫'],
                '–¥–µ—Ä–µ–≤—è–Ω–Ω—ã–π': ['–¥–µ—Ä–µ–≤—è–Ω–Ω—ã–π', '–¥–µ—Ä–µ–≤—è–Ω–Ω', '–¥–µ—Ä–µ–≤–æ'],
                '—Ö—Ä—É—â–µ–≤—Å–∫–∏–π': ['—Ö—Ä—É—â–µ–≤—Å–∫', '—Ö—Ä—É—â', '—Ö—Ä—É—â—ë–≤'],
                '—Å—Ç–∞–ª–∏–Ω—Å–∫–∏–π': ['—Å—Ç–∞–ª–∏–Ω—Å–∫', '—Å—Ç–∞–ª–∏–Ω'],
                '–±—Ä–µ–∂–Ω–µ–≤—Å–∫–∏–π': ['–±—Ä–µ–∂–Ω–µ–≤—Å–∫', '–±—Ä–µ–∂–Ω–µ–≤'],
            }
            
            for building_type, keywords in direct_keywords.items():
                for keyword in keywords:
                    if keyword in page_text_lower:
                        return building_type
            
            # 3. –ò—â–µ–º –≤ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞—Ö
            features_selectors = [
                '[data-name="Features"]',
                '[data-name="ObjectSummary"]',
                '.a10a3f92e9--container--2F3KV',
                '.a10a3f92e9--item--3dG_0',
            ]
            
            for selector in features_selectors:
                elements = soup.select(selector)
                for elem in elements:
                    text = elem.get_text().lower()
                    lines = text.split('\n')
                    for line in lines:
                        line = line.strip()
                        if '—Ç–∏–ø –¥–æ–º–∞' in line or '—Ç–∏–ø –∑–¥–∞–Ω–∏—è' in line or '–º–∞—Ç–µ—Ä–∏–∞–ª —Å—Ç–µ–Ω' in line:
                            if '–ø–∞–Ω–µ–ª—å' in line:
                                return '–ø–∞–Ω–µ–ª—å–Ω—ã–π'
                            elif '–∫–∏—Ä–ø–∏—á' in line:
                                return '–∫–∏—Ä–ø–∏—á–Ω—ã–π'
                            elif '–º–æ–Ω–æ–ª–∏—Ç' in line:
                                return '–º–æ–Ω–æ–ª–∏—Ç–Ω—ã–π'
                            elif '–±–ª–æ–∫' in line:
                                return '–±–ª–æ—á–Ω—ã–π'
                            elif '–¥–µ—Ä–µ–≤–æ' in line:
                                return '–¥–µ—Ä–µ–≤—è–Ω–Ω—ã–π'
                            elif '—Å—Ç–∞–ª–∏–Ω' in line:
                                return '—Å—Ç–∞–ª–∏–Ω—Å–∫–∏–π'
                            elif '—Ö—Ä—É—â' in line:
                                return '—Ö—Ä—É—â–µ–≤—Å–∫–∏–π'
                            elif '–±—Ä–µ–∂–Ω–µ–≤' in line:
                                return '–±—Ä–µ–∂–Ω–µ–≤—Å–∫–∏–π'
            
            # 4. –ê–Ω–∞–ª–∏–∑ –∞–¥—Ä–µ—Å–∞ –∏ —Ä–∞–π–æ–Ω–∞
            address = self.get_element_text('[data-name="GeoLabel"]') or ''
            address_lower = address.lower()
            
            # –î–ª—è –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ä–∞–π–æ–Ω–æ–≤ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø–∏—á–Ω—ã–π —Ç–∏–ø –¥–æ–º–æ–≤
            if '–≥—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π' in address_lower or '–∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫' in address_lower:
                # –ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–π —Ä–∞–π–æ–Ω - –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø–∞–Ω–µ–ª—å–Ω—ã–µ –¥–æ–º–∞ —Å–µ—Ä–∏–∏ 1–õ–ì-606
                return '–ø–∞–Ω–µ–ª—å–Ω—ã–π'
            elif any(word in address_lower for word in ['–Ω–µ–≤—Å–∫–∏–π', '–ª–∏—Ç–µ–π–Ω—ã–π', '—Å–∞–¥–æ–≤–∞—è', '–≤–∞—Å–∏–ª—å–µ–≤—Å–∫–∏–π']):
                # –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π —Ü–µ–Ω—Ç—Ä - —á–∞—â–µ –∫–∏—Ä–ø–∏—á–Ω—ã–µ
                return '–∫–∏—Ä–ø–∏—á–Ω—ã–π'
            elif any(word in address_lower for word in ['–∫—É–ø—á–∏–Ω–æ', '–ø—Ä–æ—Å–ø–µ–∫—Ç —Å–ª–∞–≤—ã', '–º–æ—Å–∫–æ–≤—Å–∫–∞—è']):
                # –°–ø–∞–ª—å–Ω—ã–µ —Ä–∞–π–æ–Ω—ã - –º–Ω–æ–≥–æ –ø–∞–Ω–µ–ª—å–Ω—ã—Ö
                return '–ø–∞–Ω–µ–ª—å–Ω—ã–π'
            
            # 5. –ê–Ω–∞–ª–∏–∑ –ø–æ –≥–æ–¥—É –ø–æ—Å—Ç—Ä–æ–π–∫–∏ (–µ—Å–ª–∏ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏)
            year = self.extract_year_built_improved(soup)
            if year:
                if 1956 <= year <= 1985:
                    # –•—Ä—É—â–µ–≤–∫–∏ –∏ –±—Ä–µ–∂–Ω–µ–≤–∫–∏ - –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø–∞–Ω–µ–ª—å–Ω—ã–µ
                    if 1956 <= year <= 1965:
                        return '—Ö—Ä—É—â–µ–≤—Å–∫–∏–π'
                    else:
                        return '–ø–∞–Ω–µ–ª—å–Ω—ã–π'
                elif 1930 <= year <= 1955:
                    # –°—Ç–∞–ª–∏–Ω–∫–∏ - –æ–±—ã—á–Ω–æ –∫–∏—Ä–ø–∏—á–Ω—ã–µ
                    return '—Å—Ç–∞–ª–∏–Ω—Å–∫–∏–π'
                elif year >= 1990:
                    # –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–æ–º–∞ - —á–∞—â–µ –ø–∞–Ω–µ–ª—å–Ω—ã–µ –∏–ª–∏ –º–æ–Ω–æ–ª–∏—Ç–Ω—ã–µ
                    # –î–ª—è –°–ü–± –ø–æ—Å–ª–µ 2000 –º–Ω–æ–≥–æ –ø–∞–Ω–µ–ª—å–Ω—ã—Ö
                    return '–ø–∞–Ω–µ–ª—å–Ω—ã–π'
            
            # 6. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –°–ü–± - –ø–∞–Ω–µ–ª—å–Ω—ã–π (—Å–∞–º—ã–π —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–π)
            return '–ø–∞–Ω–µ–ª—å–Ω—ã–π'
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Ç–∏–ø–∞ –¥–æ–º–∞: {e}")
            return None
    
    def extract_property_category_improved(self, soup):
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏: –≤—Ç–æ—Ä–∏—á–∫–∞ –∏–ª–∏ –Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞ - –£–õ–£–ß–®–ï–ù–ù–´–ô –ú–ï–¢–û–î"""
        try:
            page_text = soup.get_text()
            page_text_lower = page_text.lower()
            
            # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ–¥ —Å–¥–∞—á–∏ (—Å–∞–º—ã–π –Ω–∞–¥–µ–∂–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫)
            year_patterns = [
                r'—Å–¥–∞—á–∞.*?(\d{4})',
                r'–≥–æ–¥.*?—Å–¥–∞—á–∏.*?(\d{4})',
                r'(\d{4})\s*–≥–æ–¥.*?—Å–¥–∞—á–∏',
                r'–≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å.*?(\d{4})',
                r'–∑–∞—Å–µ–ª–µ–Ω–∏–µ.*?(\d{4})',
                r'–∫–≤–∞—Ä—Ç–∏—Ä–∞.*?—Å–¥–∞–µ—Ç—Å—è.*?(\d{4})',
                r'–ø–æ—Å—Ç—Ä–æ–µ–Ω.*?(\d{4})',
                r'–¥–æ–º.*?(\d{4}).*?–≥–æ–¥–∞',
            ]
            
            current_year = datetime.now().year
            
            for pattern in year_patterns:
                match = re.search(pattern, page_text, re.IGNORECASE)
                if match:
                    year = int(match.group(1))
                    # –ï—Å–ª–∏ –≥–æ–¥ —Å–¥–∞—á–∏ –≤ –±—É–¥—É—â–µ–º - —ç—Ç–æ –Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞
                    if year > current_year:
                        return '–Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞'
                    # –ï—Å–ª–∏ –≥–æ–¥ —Å–¥–∞—á–∏ –æ—á–µ–Ω—å –Ω–µ–¥–∞–≤–Ω–∏–π (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 –≥–æ–¥–∞) - —Ç–æ–∂–µ –Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞
                    elif year >= current_year - 1:
                        # –ù–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥—Ä—É–≥–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
                        if '–≤—Ç–æ—Ä–∏—á' not in page_text_lower:
                            return '–Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞'
                    # –ï—Å–ª–∏ –≥–æ–¥ —Å–¥–∞—á–∏ –≤ –ø—Ä–æ—à–ª–æ–º - —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –≤—Ç–æ—Ä–∏—á–∫–∞
                    else:
                        return '–≤—Ç–æ—Ä–∏—á–∫–∞'
            
            # 2. –°—á–∏—Ç–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            new_building_keywords = [
                '–Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞', '–Ω–æ–≤—ã–π –¥–æ–º', '–Ω–æ–≤—ã–π –∫–æ–º–ø–ª–µ–∫—Å', '—Å—Ç—Ä–æ–π–∫–∞',
                '—Å–¥–∞–µ—Ç—Å—è –≤', '–≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å', '–∑–∞—Å–µ–ª–µ–Ω–∏–µ —Å', '—Å—Ä–æ–∫ —Å–¥–∞—á–∏',
                '–ø–µ—Ä–≤–∏—á–∫–∞', '–ø–µ—Ä–≤–∏—á–Ω—ã–π —Ä—ã–Ω–æ–∫', '–æ—Ç –∑–∞—Å—Ç—Ä–æ–π—â–∏–∫–∞',
                '–∫–≤–∞—Ä—Ç–∏—Ä–∞ —Å –æ—Ç–¥–µ–ª–∫–æ–π', '—Å —á–∏—Å—Ç–æ–≤–æ–π –æ—Ç–¥–µ–ª–∫–æ–π',
                '–≤ —Ç–æ–ª—å–∫–æ —á—Ç–æ –ø–æ—Å—Ç—Ä–æ–µ–Ω–Ω–æ–º –¥–æ–º–µ', '–≤ –Ω–æ–≤–æ–º –¥–æ–º–µ',
                '–æ—Ç–¥–µ–ª–∫–∞ –æ—Ç –∑–∞—Å—Ç—Ä–æ–π—â–∏–∫–∞', '—Å —Ä–µ–º–æ–Ω—Ç–æ–º –æ—Ç –∑–∞—Å—Ç—Ä–æ–π—â–∏–∫–∞',
                '–ø–µ—Ä–≤–∏—á–Ω–∞—è –ø—Ä–æ–¥–∞–∂–∞', '–ø—Ä—è–º–∞—è –ø—Ä–æ–¥–∞–∂–∞ –æ—Ç –∑–∞—Å—Ç—Ä–æ–π—â–∏–∫–∞'
            ]
            
            old_building_keywords = [
                '–≤—Ç–æ—Ä–∏—á–∫–∞', '–≤—Ç–æ—Ä–∏—á–Ω—ã–π —Ä—ã–Ω–æ–∫', '–≤—Ç–æ—Ä–∏—á–Ω–æ–µ –∂–∏–ª—å–µ',
                '—Ö—Ä—É—â–µ–≤–∫–∞', '—Å—Ç–∞–ª–∏–Ω–∫–∞', '–±—Ä–µ–∂–Ω–µ–≤–∫–∞',
                '–≤–æ –≤—Ç–æ—Ä–∏—á–Ω–æ–º —Ñ–æ–Ω–¥–µ', '—Ä–∞–Ω–µ–µ –Ω–µ –ø—Ä–æ–∂–∏–≤–∞–ª',
                '—Ä–∞–Ω–µ–µ –ø—Ä–æ–∂–∏–≤–∞–ª–∏', '–±—ã–≤—à–µ–µ –∂–∏–ª—å–µ',
                '–≤ –¥–æ–º–µ —Å–æ–≤–µ—Ç—Å–∫–æ–π –ø–æ—Å—Ç—Ä–æ–π–∫–∏', '–¥–æ–º —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ–Ω–¥–∞'
            ]
            
            new_count = sum(1 for keyword in new_building_keywords if keyword in page_text_lower)
            old_count = sum(1 for keyword in old_building_keywords if keyword in page_text_lower)
            
            if new_count > old_count:
                return '–Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞'
            elif old_count > new_count:
                return '–≤—Ç–æ—Ä–∏—á–∫–∞'
            
            # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏ –¥–æ–º–∞
            year_built = self.extract_year_built_improved(soup)
            if year_built:
                if year_built >= current_year - 3:  # –î–æ–º–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 3 –ª–µ—Ç
                    return '–Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞'
                else:
                    return '–≤—Ç–æ—Ä–∏—á–∫–∞'
            
            # 4. –ê–Ω–∞–ª–∏–∑ URL
            current_url = self.driver.current_url if self.driver else ""
            if 'newbuilding' in current_url.lower():
                return '–Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞'
            
            # 5. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∑–∞—Å—Ç—Ä–æ–π—â–∏–∫–µ
            if any(word in page_text_lower for word in ['–∑–∞—Å—Ç—Ä–æ–π—â–∏–∫', '—Å—Ç—Ä–æ–π–∫–æ–º–ø–∞–Ω–∏—è', '–¥–µ–≤–µ–ª–æ–ø–µ—Ä']):
                return '–Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞'
            
            # 6. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –¥–æ–º–∞ (–∫–æ—Å–≤–µ–Ω–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫)
            building_type = self.extract_building_type_improved(soup)
            if building_type in ['—Ö—Ä—É—â–µ–≤—Å–∫–∏–π', '—Å—Ç–∞–ª–∏–Ω—Å–∫–∏–π', '–±—Ä–µ–∂–Ω–µ–≤—Å–∫–∏–π']:
                return '–≤—Ç–æ—Ä–∏—á–∫–∞'
            
            # 7. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –æ–±—ä—è–≤–ª–µ–Ω–∏–π –æ –ø—Ä–æ–¥–∞–∂–µ - –≤—Ç–æ—Ä–∏—á–∫–∞
            return '–≤—Ç–æ—Ä–∏—á–∫–∞'
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {e}")
            return '–≤—Ç–æ—Ä–∏—á–∫–∞'
    
    def extract_property_type(self):
        """–ò–∑–≤–ª–µ—á—å —Ç–∏–ø –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏"""
        try:
            current_url = self.driver.current_url
            if 'newbuilding' in current_url:
                return '–Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞'
            else:
                return '–≤—Ç–æ—Ä–∏—á–∫–∞'
        except:
            return '–≤—Ç–æ—Ä–∏—á–∫–∞'
    
    def extract_seller_type(self):
        """–ò–∑–≤–ª–µ—á—å —Ç–∏–ø –ø—Ä–æ–¥–∞–≤—Ü–∞"""
        try:
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-name="Owner"]')
            for elem in elements:
                text = elem.text.lower()
                if '—Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫' in text or '–≤–ª–∞–¥–µ–ª–µ—Ü' in text:
                    return '—Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫'
                elif '–∞–≥–µ–Ω—Ç—Å—Ç–≤–æ' in text or '—Ä–∏–µ–ª—Ç–æ—Ä' in text:
                    return '–∞–≥–µ–Ω—Ç—Å—Ç–≤–æ'
        except:
            pass
        return None
    
    def extract_district(self):
        """–ò–∑–≤–ª–µ—á—å —Ä–∞–π–æ–Ω"""
        try:
            address = self.get_element_text('[data-name="GeoLabel"]') or self.get_element_text('[data-name="AddressContainer"]')
            if address:
                parts = address.split(',')
                for part in parts:
                    part = part.strip()
                    if '—Ä-–Ω' in part:
                        return part.replace('—Ä-–Ω', '').strip()
                    elif '—Ä–∞–π–æ–Ω' in part:
                        return part.replace('—Ä–∞–π–æ–Ω', '').strip()
                    
                if len(parts) > 1:
                    return parts[1].strip()
        except:
            pass
        return None
    
    def extract_metro_station_improved(self, soup):
        """–ò–∑–≤–ª–µ—á—å —Å—Ç–∞–Ω—Ü–∏—é –º–µ—Ç—Ä–æ - –£–õ–£–ß–®–ï–ù–ù–´–ô –ú–ï–¢–û–î"""
        try:
            # 1. –ò—â–µ–º –≤ —ç–ª–µ–º–µ–Ω—Ç–∞—Ö –¶–ò–ê–ù —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –º–µ—Ç—Ä–æ
            metro_selectors = [
                'a[href*="underground"]',
                '[data-name="UndergroundStation"]',
                '[data-name="GeoUnderground"]',
                '[class*="underground"]',
                '[class*="metro"]',
                '.underground-item',
                '.metro-item',
            ]
            
            for selector in metro_selectors:
                elements = soup.select(selector)
                for elem in elements:
                    text = elem.get_text(strip=True)
                    if text and len(text) < 50 and '–º–µ—Ç—Ä–æ' in text.lower():
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞–Ω—Ü–∏–∏
                        station = text.replace('–º–µ—Ç—Ä–æ', '').replace('–º.', '').strip()
                        # –£–±–∏—Ä–∞–µ–º –≤—Ä–µ–º—è –≤ —Å–∫–æ–±–∫–∞—Ö
                        station = re.sub(r'\s*\([^)]+\)', '', station).strip()
                        if station:
                            return station
            
            # 2. –ò—â–µ–º –≤ JSON-LD
            json_ld = soup.find('script', type='application/ld+json')
            if json_ld and json_ld.string:
                try:
                    data = json.loads(json_ld.string)
                    if 'description' in data:
                        desc = data['description']
                        # –°–ø–∏—Å–æ–∫ —Å—Ç–∞–Ω—Ü–∏–π –º–µ—Ç—Ä–æ –°–ü–±
                        stations_spb = [
                            '–ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∞—è', '–ì—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π –ø—Ä–æ—Å–ø–µ–∫—Ç', '–î–µ–≤—è—Ç–∫–∏–Ω–æ',
                            '–ü–æ–ª–∏—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è', '–ü–ª–æ—â–∞–¥—å –ú—É–∂–µ—Å—Ç–≤–∞', '–õ–µ—Å–Ω–∞—è',
                            '–í—ã–±–æ—Ä–≥—Å–∫–∞—è', '–ü–ª–æ—â–∞–¥—å –õ–µ–Ω–∏–Ω–∞', '–ß–µ—Ä–Ω—ã—à–µ–≤—Å–∫–∞—è',
                            '–ü–ª–æ—â–∞–¥—å –í–æ—Å—Å—Ç–∞–Ω–∏—è', '–í–ª–∞–¥–∏–º–∏—Ä—Å–∫–∞—è', '–ü—É—à–∫–∏–Ω—Å–∫–∞—è',
                            '–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∏–Ω—Å—Ç–∏—Ç—É—Ç', '–ë–∞–ª—Ç–∏–π—Å–∫–∞—è', '–ù–∞—Ä–≤—Å–∫–∞—è',
                            '–ö–∏—Ä–æ–≤—Å–∫–∏–π –∑–∞–≤–æ–¥', '–ê–≤—Ç–æ–≤–æ', '–õ–µ–Ω–∏–Ω—Å–∫–∏–π –ø—Ä–æ—Å–ø–µ–∫—Ç',
                            '–ü—Ä–æ—Å–ø–µ–∫—Ç –í–µ—Ç–µ—Ä–∞–Ω–æ–≤', '–ü–∞—Ä–∫ –ü–æ–±–µ–¥—ã', '–≠–ª–µ–∫—Ç—Ä–æ—Å–∏–ª–∞',
                            '–ú–æ—Å–∫–æ–≤—Å–∫–∞—è', '–ó–≤—ë–∑–¥–Ω–∞—è', '–ö—É–ø—á–∏–Ω–æ', '–õ–∞–¥–æ–∂—Å–∫–∞—è',
                            '–ü—Ä–æ—Å–ø–µ–∫—Ç –ë–æ–ª—å—à–µ–≤–∏–∫–æ–≤', '–£–ª–∏—Ü–∞ –î—ã–±–µ–Ω–∫–æ'
                        ]
                        
                        for station in stations_spb:
                            if station in desc:
                                return station
                except:
                    pass
            
            # 3. –ò—â–µ–º –ø–æ —Ç–µ–∫—Å—Ç—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            page_text = soup.get_text()
            
            # –°–ø–∏—Å–æ–∫ —Å—Ç–∞–Ω—Ü–∏–π –¥–ª—è –ø–æ–∏—Å–∫–∞
            common_stations = [
                '–ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∞—è', '–ì—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π –ø—Ä–æ—Å–ø–µ–∫—Ç', '–ü–æ–ª–∏—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è',
                '–õ–µ—Å–Ω–∞—è', '–í—ã–±–æ—Ä–≥—Å–∫–∞—è', '–ü–ª–æ—â–∞–¥—å –õ–µ–Ω–∏–Ω–∞', '–ß–µ—Ä–Ω—ã—à–µ–≤—Å–∫–∞—è',
                '–ü–ª–æ—â–∞–¥—å –í–æ—Å—Å—Ç–∞–Ω–∏—è', '–í–ª–∞–¥–∏–º–∏—Ä—Å–∫–∞—è', '–ü—É—à–∫–∏–Ω—Å–∫–∞—è',
                '–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∏–Ω—Å—Ç–∏—Ç—É—Ç', '–ë–∞–ª—Ç–∏–π—Å–∫–∞—è', '–ù–∞—Ä–≤—Å–∫–∞—è',
                '–ö–∏—Ä–æ–≤—Å–∫–∏–π –∑–∞–≤–æ–¥', '–ê–≤—Ç–æ–≤–æ'
            ]
            
            for station in common_stations:
                if station in page_text:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –∏–º–µ–Ω–Ω–æ —Å—Ç–∞–Ω—Ü–∏—è –º–µ—Ç—Ä–æ, –∞ –Ω–µ —á–∞—Å—Ç—å –∞–¥—Ä–µ—Å–∞
                    context = page_text[page_text.find(station)-50:page_text.find(station)+50]
                    if '–º–µ—Ç—Ä–æ' in context.lower() or '—Å—Ç–∞–Ω—Ü–∏—è' in context.lower():
                        return station
            
            # 4. –ò—â–µ–º –≤ –±–ª–æ–∫–µ "–ë–ª–∏–∂–∞–π—à–µ–µ –º–µ—Ç—Ä–æ"
            for elem in soup.find_all(['div', 'p', 'span']):
                text = elem.get_text(strip=True)
                if '–±–ª–∏–∂–∞–π—à–µ–µ –º–µ—Ç—Ä–æ' in text.lower() or '—Å—Ç–∞–Ω—Ü–∏—è –º–µ—Ç—Ä–æ' in text.lower():
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ —Å–ª–µ–¥—É—é—â–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
                    next_elem = elem.find_next()
                    if next_elem:
                        station_text = next_elem.get_text(strip=True)
                        # –£–±–∏—Ä–∞–µ–º –≤—Ä–µ–º—è –∏ –ª–∏—à–Ω–∏–µ —Å–ª–æ–≤–∞
                        station = re.sub(r'\s*\([^)]+\)', '', station_text)
                        station = station.replace('–º–µ—Ç—Ä–æ', '').strip()
                        if station and len(station) < 30:
                            return station
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –º–µ—Ç—Ä–æ: {e}")
        return None
    
    def extract_metro_station_improved(self, soup):
        """–ò–∑–≤–ª–µ—á—å —Å—Ç–∞–Ω—Ü–∏—é –º–µ—Ç—Ä–æ - –£–õ–£–ß–®–ï–ù–ù–´–ô –ú–ï–¢–û–î"""
        try:
            page_text = soup.get_text()
            
            # 1. –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≤ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö –¶–ò–ê–ù
            metro_selectors = [
                'a[href*="underground"]',
                '[data-name="UndergroundStation"]',
                '[data-name="GeoUnderground"]',
                '[class*="underground"]',
                '[class*="metro"]',
                '.underground-item',
                '.metro-item',
                '[data-name="UndergroundGeneralInfo"]',
                '[data-name="TransportInfo"]',
            ]
            
            for selector in metro_selectors:
                try:
                    elements = soup.select(selector)
                    for elem in elements:
                        text = elem.get_text(strip=True)
                        if text and len(text) < 50:
                            # –£–±–∏—Ä–∞–µ–º –≤—Ä–µ–º—è –¥–æ –º–µ—Ç—Ä–æ
                            station = re.sub(r'\(\d+\s*–º–∏–Ω\)', '', text)
                            station = re.sub(r'\d+\s*–º–∏–Ω', '', station)
                            station = re.sub(r'\d+', '', station)  # –£–±–∏—Ä–∞–µ–º —Ü–∏—Ñ—Ä—ã
                            station = station.replace('–º–µ—Ç—Ä–æ', '').replace('–º.', '').replace('—Å—Ç.', '').strip()
                            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
                            station = re.sub(r'[^\w\s\-]', '', station).strip()
                            
                            if station and len(station) > 2 and len(station) < 30:
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –∏ –Ω–µ —Ç–æ–ª—å–∫–æ –≤—Ä–µ–º—è
                                if not re.match(r'^\d+.*–º–∏–Ω', station):
                                    return station
                except:
                    continue
            
            # 2. –ò—â–µ–º —Å—Ç–∞–Ω—Ü–∏–∏ –º–µ—Ç—Ä–æ –≤ —Ç–µ–∫—Å—Ç–µ –ø–æ –∏–∑–≤–µ—Å—Ç–Ω—ã–º –Ω–∞–∑–≤–∞–Ω–∏—è–º
            # –°–ø–∏—Å–æ–∫ —Å—Ç–∞–Ω—Ü–∏–π –º–µ—Ç—Ä–æ –°–ü–± (–≤—Å–µ –ª–∏–Ω–∏–∏)
            stations_spb = [
                # –õ–∏–Ω–∏—è 1 (–ö–∏—Ä–æ–≤—Å–∫–æ-–í—ã–±–æ—Ä–≥—Å–∫–∞—è)
                '–î–µ–≤—è—Ç–∫–∏–Ω–æ', '–ì—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π –ø—Ä–æ—Å–ø–µ–∫—Ç', '–ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∞—è',
                '–ü–æ–ª–∏—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è', '–ü–ª–æ—â–∞–¥—å –ú—É–∂–µ—Å—Ç–≤–∞', '–õ–µ—Å–Ω–∞—è',
                '–í—ã–±–æ—Ä–≥—Å–∫–∞—è', '–ü–ª–æ—â–∞–¥—å –õ–µ–Ω–∏–Ω–∞', '–ß–µ—Ä–Ω—ã—à–µ–≤—Å–∫–∞—è',
                '–ü–ª–æ—â–∞–¥—å –í–æ—Å—Å—Ç–∞–Ω–∏—è', '–í–ª–∞–¥–∏–º–∏—Ä—Å–∫–∞—è', '–ü—É—à–∫–∏–Ω—Å–∫–∞—è',
                '–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∏–Ω—Å—Ç–∏—Ç—É—Ç', '–ë–∞–ª—Ç–∏–π—Å–∫–∞—è', '–ù–∞—Ä–≤—Å–∫–∞—è',
                '–ö–∏—Ä–æ–≤—Å–∫–∏–π –∑–∞–≤–æ–¥', '–ê–≤—Ç–æ–≤–æ', '–õ–µ–Ω–∏–Ω—Å–∫–∏–π –ø—Ä–æ—Å–ø–µ–∫—Ç',
                '–ü—Ä–æ—Å–ø–µ–∫—Ç –í–µ—Ç–µ—Ä–∞–Ω–æ–≤', '–ü–∞—Ä–∫ –ü–æ–±–µ–¥—ã', '–≠–ª–µ–∫—Ç—Ä–æ—Å–∏–ª–∞',
                '–ú–æ—Å–∫–æ–≤—Å–∫–∞—è', '–ó–≤—ë–∑–¥–Ω–∞—è', '–ö—É–ø—á–∏–Ω–æ',
                
                # –õ–∏–Ω–∏—è 2 (–ú–æ—Å–∫–æ–≤—Å–∫–æ-–ü–µ—Ç—Ä–æ–≥—Ä–∞–¥—Å–∫–∞—è)
                '–ü–∞—Ä–Ω–∞—Å', '–ü—Ä–æ—Å–ø–µ–∫—Ç –ü—Ä–æ—Å–≤–µ—â–µ–Ω–∏—è', '–û–∑–µ—Ä–∫–∏',
                '–£–¥–µ–ª—å–Ω–∞—è', '–ü–∏–æ–Ω–µ—Ä—Å–∫–∞—è', '–ß—ë—Ä–Ω–∞—è —Ä–µ—á–∫–∞',
                '–ü–µ—Ç—Ä–æ–≥—Ä–∞–¥—Å–∫–∞—è', '–ì–æ—Ä—å–∫–æ–≤—Å–∫–∞—è', '–ù–µ–≤—Å–∫–∏–π –ø—Ä–æ—Å–ø–µ–∫—Ç',
                '–°–µ–Ω–Ω–∞—è –ø–ª–æ—â–∞–¥—å', '–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∏–Ω—Å—Ç–∏—Ç—É—Ç',
                '–§—Ä—É–Ω–∑–µ–Ω—Å–∫–∞—è', '–ú–æ—Å–∫–æ–≤—Å–∫–∏–µ –≤–æ—Ä–æ—Ç–∞', '–≠–ª–µ–∫—Ç—Ä–æ—Å–∏–ª–∞',
                '–ü–∞—Ä–∫ –ü–æ–±–µ–¥—ã', '–ú–æ—Å–∫–æ–≤—Å–∫–∞—è', '–ó–≤—ë–∑–¥–Ω–∞—è', '–ö—É–ø—á–∏–Ω–æ',
                
                # –õ–∏–Ω–∏—è 3 (–ù–µ–≤—Å–∫–æ-–í–∞—Å–∏–ª–µ–æ—Å—Ç—Ä–æ–≤—Å–∫–∞—è)
                '–ë–µ–≥–æ–≤–∞—è', '–ó–µ–Ω–∏—Ç', '–ü—Ä–∏–º–æ—Ä—Å–∫–∞—è', '–í–∞—Å–∏–ª–µ–æ—Å—Ç—Ä–æ–≤—Å–∫–∞—è',
                '–ì–æ—Å—Ç–∏–Ω—ã–π –¥–≤–æ—Ä', '–ú–∞—è–∫–æ–≤—Å–∫–∞—è', '–ü–ª–æ—â–∞–¥—å –ê–ª–µ–∫—Å–∞–Ω–¥—Ä–∞ –ù–µ–≤—Å–∫–æ–≥–æ',
                '–ï–ª–∏–∑–∞—Ä–æ–≤—Å–∫–∞—è', '–õ–æ–º–æ–Ω–æ—Å–æ–≤—Å–∫–∞—è', '–ü—Ä–æ–ª–µ—Ç–∞—Ä—Å–∫–∞—è',
                '–û–±—É—Ö–æ–≤–æ', '–†—ã–±–∞—Ü–∫–æ–µ',
                
                # –õ–∏–Ω–∏—è 4 (–ü—Ä–∞–≤–æ–±–µ—Ä–µ–∂–Ω–∞—è)
                '–°–ø–∞—Å—Å–∫–∞—è', '–î–æ—Å—Ç–æ–µ–≤—Å–∫–∞—è', '–õ–∏–≥–æ–≤—Å–∫–∏–π –ø—Ä–æ—Å–ø–µ–∫—Ç',
                '–ü–ª–æ—â–∞–¥—å –ê–ª–µ–∫—Å–∞–Ω–¥—Ä–∞ –ù–µ–≤—Å–∫–æ–≥–æ', '–ù–æ–≤–æ—á–µ—Ä–∫–∞—Å—Å–∫–∞—è',
                '–õ–∞–¥–æ–∂—Å–∫–∞—è', '–ü—Ä–æ—Å–ø–µ–∫—Ç –ë–æ–ª—å—à–µ–≤–∏–∫–æ–≤', '–£–ª–∏—Ü–∞ –î—ã–±–µ–Ω–∫–æ',
                
                # –õ–∏–Ω–∏—è 5 (–§—Ä—É–Ω–∑–µ–Ω—Å–∫–æ-–ü—Ä–∏–º–æ—Ä—Å–∫–∞—è)
                '–ö–æ–º–µ–Ω–¥–∞–Ω—Ç—Å–∫–∏–π –ø—Ä–æ—Å–ø–µ–∫—Ç', '–°—Ç–∞—Ä–∞—è –î–µ—Ä–µ–≤–Ω—è', '–ö—Ä–µ—Å—Ç–æ–≤—Å–∫–∏–π –æ—Å—Ç—Ä–æ–≤',
                '–ß–∫–∞–ª–æ–≤—Å–∫–∞—è', '–°–ø–æ—Ä—Ç–∏–≤–Ω–∞—è', '–ê–¥–º–∏—Ä–∞–ª—Ç–µ–π—Å–∫–∞—è',
                '–°–∞–¥–æ–≤–∞—è', '–ó–≤–µ–Ω–∏–≥–æ—Ä–æ–¥—Å–∫–∞—è', '–û–±–≤–æ–¥–Ω—ã–π –∫–∞–Ω–∞–ª',
                '–í–æ–ª–∫–æ–≤—Å–∫–∞—è', '–ë—É—Ö–∞—Ä–µ—Å—Ç—Å–∫–∞—è', '–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–∞—è',
                
                # –ù–æ–≤—ã–µ —Å—Ç–∞–Ω—Ü–∏–∏ –∏ –ø–ª–∞–Ω–∏—Ä—É–µ–º—ã–µ
                '–ì–æ—Ä–Ω—ã–π –∏–Ω—Å—Ç–∏—Ç—É—Ç', '–¢–µ–∞—Ç—Ä–∞–ª—å–Ω–∞—è', '–®—É—à–∞—Ä—ã'
            ]
            
            # –ò—â–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–∞–Ω—Ü–∏–π –≤ —Ç–µ–∫—Å—Ç–µ
            for station in stations_spb:
                if station in page_text:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç, —á—Ç–æ–±—ã —É–±–µ–¥–∏—Ç—å—Å—è —á—Ç–æ —ç—Ç–æ –∏–º–µ–Ω–Ω–æ —Å—Ç–∞–Ω—Ü–∏—è –º–µ—Ç—Ä–æ
                    context_start = page_text.find(station) - 50
                    context_end = page_text.find(station) + 50
                    if context_start < 0:
                        context_start = 0
                    if context_end > len(page_text):
                        context_end = len(page_text)
                    
                    context = page_text[context_start:context_end].lower()
                    # –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å —Å–ª–æ–≤–∞ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –º–µ—Ç—Ä–æ
                    if any(word in context for word in ['–º–µ—Ç—Ä–æ', '—Å—Ç–∞–Ω—Ü–∏—è', '–±–ª–∏–∂–∞–π—à–µ–µ', '–º.', '—Å—Ç.']):
                        return station
            
            # 3. –ò—â–µ–º –≤ –±–ª–æ–∫–µ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–µ
            transport_blocks = soup.find_all(['div', 'section'], class_=lambda x: x and any(
                word in str(x).lower() for word in ['transport', 'commute', 'infrastructure', 'location']
            ))
            
            for block in transport_blocks:
                text = block.get_text()
                # –ò—â–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –º–µ—Ç—Ä–æ
                if '–º–µ—Ç—Ä–æ' in text.lower():
                    lines = text.split('\n')
                    for line in lines:
                        line = line.strip()
                        # –ò—â–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞–Ω—Ü–∏–∏ –≤ —Å—Ç—Ä–æ–∫–µ
                        for station in stations_spb:
                            if station in line:
                                # –û—á–∏—â–∞–µ–º –æ—Ç –≤—Ä–µ–º–µ–Ω–∏ –∏ –ª–∏—à–Ω–µ–≥–æ
                                clean_line = re.sub(r'\(\d+\s*–º–∏–Ω\)', '', line)
                                clean_line = re.sub(r'\d+\s*–º–∏–Ω', '', clean_line)
                                if station in clean_line:
                                    return station
            
            # 4. –ò—â–µ–º –≤ JSON-LD –¥–∞–Ω–Ω—ã—Ö (–µ—Å–ª–∏ –µ—Å—Ç—å)
            json_ld = soup.find('script', type='application/ld+json')
            if json_ld and json_ld.string:
                try:
                    data = json.loads(json_ld.string)
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ –ø–æ–ª—è
                    for field in ['description', 'name', 'address']:
                        if field in data:
                            field_text = str(data[field])
                            for station in stations_spb:
                                if station in field_text:
                                    return station
                except:
                    pass
            
            # 5. –ò—â–µ–º –ø–æ –∞–¥—Ä–µ—Å—É (–∫–æ—Å–≤–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥)
            address = self.extract_district() or ''
            address_lower = str(address).lower()
            
            # –ú–∞–ø–ø–∏–Ω–≥ —Ä–∞–π–æ–Ω–æ–≤ –Ω–∞ –±–ª–∏–∂–∞–π—à–∏–µ —Å—Ç–∞–Ω—Ü–∏–∏
            district_station_map = {
                '—Ñ—Ä—É–Ω–∑–µ–Ω—Å–∫–∏–π': ['–ö—É–ø—á–∏–Ω–æ', '–ó–≤—ë–∑–¥–Ω–∞—è', '–ú–æ—Å–∫–æ–≤—Å–∫–∞—è', '–≠–ª–µ–∫—Ç—Ä–æ—Å–∏–ª–∞', '–ü–∞—Ä–∫ –ü–æ–±–µ–¥—ã', '–§—Ä—É–Ω–∑–µ–Ω—Å–∫–∞—è'],
                '–∫–∞–ª–∏–Ω–∏–Ω—Å–∫–∏–π': ['–ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∞—è', '–ì—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π –ø—Ä–æ—Å–ø–µ–∫—Ç', '–ü–æ–ª–∏—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è'],
                '–≤—ã–±–æ—Ä–≥—Å–∫–∏–π': ['–û–∑–µ—Ä–∫–∏', '–ü—Ä–æ—Å–ø–µ–∫—Ç –ü—Ä–æ—Å–≤–µ—â–µ–Ω–∏—è', '–ü–∞—Ä–Ω–∞—Å', '–£–¥–µ–ª—å–Ω–∞—è'],
                '–ø—Ä–∏–º–æ—Ä—Å–∫–∏–π': ['–ö–æ–º–µ–Ω–¥–∞–Ω—Ç—Å–∫–∏–π –ø—Ä–æ—Å–ø–µ–∫—Ç', '–°—Ç–∞—Ä–∞—è –î–µ—Ä–µ–≤–Ω—è', '–ß—ë—Ä–Ω–∞—è —Ä–µ—á–∫–∞'],
                '–ø–µ—Ç—Ä–æ–≥—Ä–∞–¥—Å–∫–∏–π': ['–ü–µ—Ç—Ä–æ–≥—Ä–∞–¥—Å–∫–∞—è', '–ì–æ—Ä—å–∫–æ–≤—Å–∫–∞—è', '–ß–∫–∞–ª–æ–≤—Å–∫–∞—è'],
                '–≤–∞—Å–∏–ª–µ–æ—Å—Ç—Ä–æ–≤—Å–∫–∏–π': ['–í–∞—Å–∏–ª–µ–æ—Å—Ç—Ä–æ–≤—Å–∫–∞—è', '–ü—Ä–∏–º–æ—Ä—Å–∫–∞—è'],
                '—Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π': ['–ù–µ–≤—Å–∫–∏–π –ø—Ä–æ—Å–ø–µ–∫—Ç', '–ì–æ—Å—Ç–∏–Ω—ã–π –¥–≤–æ—Ä', '–ü–ª–æ—â–∞–¥—å –í–æ—Å—Å—Ç–∞–Ω–∏—è'],
                '–∞–¥–º–∏—Ä–∞–ª—Ç–µ–π—Å–∫–∏–π': ['–ê–¥–º–∏—Ä–∞–ª—Ç–µ–π—Å–∫–∞—è', '–°–µ–Ω–Ω–∞—è –ø–ª–æ—â–∞–¥—å', '–°–∞–¥–æ–≤–∞—è'],
                '–º–æ—Å–∫–æ–≤—Å–∫–∏–π': ['–ú–æ—Å–∫–æ–≤—Å–∫–∞—è', '–ó–≤—ë–∑–¥–Ω–∞—è', '–ö—É–ø—á–∏–Ω–æ'],
                '–Ω–µ–≤—Å–∫–∏–π': ['–ü—Ä–æ–ª–µ—Ç–∞—Ä—Å–∫–∞—è', '–û–±—É—Ö–æ–≤–æ', '–†—ã–±–∞—Ü–∫–æ–µ', '–£–ª–∏—Ü–∞ –î—ã–±–µ–Ω–∫–æ'],
            }
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–π–æ–Ω –∏ –∏—â–µ–º —Å—Ç–∞–Ω—Ü–∏–∏ –¥–ª—è –Ω–µ–≥–æ
            for district, stations in district_station_map.items():
                if district in address_lower:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∫–∞–∫–∞—è-—Ç–æ –∏–∑ —ç—Ç–∏—Ö —Å—Ç–∞–Ω—Ü–∏–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
                    for station in stations:
                        if station in page_text:
                            return station
            
            # 6. –ò—â–µ–º —Ä—è–¥–æ–º —Å —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º –≤—Ä–µ–º–µ–Ω–∏ –¥–æ –º–µ—Ç—Ä–æ
            if self.extract_metro_time_improved(soup):
                # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –≤—Ä–µ–º—è –¥–æ –º–µ—Ç—Ä–æ, –∏—â–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä—è–¥–æ–º
                time_patterns = [
                    r'(\d+)\s*–º–∏–Ω',
                    r'\((\d+)\s*–º–∏–Ω\)',
                ]
                
                for pattern in time_patterns:
                    matches = list(re.finditer(pattern, page_text))
                    for match in matches:
                        # –ò—â–µ–º —Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–¥ –≤—Ä–µ–º–µ–Ω–µ–º (50 —Å–∏–º–≤–æ–ª–æ–≤)
                        start = max(0, match.start() - 100)
                        context = page_text[start:match.start()]
                        
                        # –ò—â–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–∞–Ω—Ü–∏–π –≤ —ç—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
                        for station in stations_spb:
                            if station in context:
                                return station
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –º–µ—Ç—Ä–æ: {e}")
        return None



    
    def save_to_database(self, data):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –±–∞–∑—É"""
        if not data or not self.conn:
            return False
        
        try:
            self.cursor.execute(
                f"SELECT price FROM {self.table_name} WHERE cian_id = %s",
                (data['cian_id'],)
            )
            
            existing = self.cursor.fetchone()
            now = datetime.now()
            
            if existing:
                old_price = existing[0]
                new_price = data.get('price')
                
                if new_price and new_price != old_price:
                    print(f"   üí± –¶–µ–Ω–∞ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å: {old_price:,} ‚Üí {new_price:,} ‚ÇΩ")
                    self.save_to_price_history(data['cian_id'], new_price, now)
                
                update_sql = f"""
                    UPDATE {self.table_name} SET
                    url = %s, title = %s, address = %s, price = %s, price_per_m2 = %s,
                    old_price = %s, area_total = %s, area_living = %s, area_kitchen = %s,
                    floor_current = %s, floor_total = %s, rooms = %s, year_built = %s,
                    building_type = %s, property_category = %s, property_type = %s, description = %s,
                    seller_type = %s, publication_date = %s, is_active = %s,
                    district = %s, metro_station = %s, metro_time = %s,
                    updated_at = %s, last_checked = %s
                    WHERE cian_id = %s
                """
                
                self.cursor.execute(update_sql, (
                    data['url'], data['title'], data['address'],
                    data['price'], data['price_per_m2'],
                    data['old_price'], data['area_total'], data['area_living'], data['area_kitchen'],
                    data['floor_current'], data['floor_total'], data['rooms'], data['year_built'],
                    data['building_type'], data['property_category'], data['property_type'], data['description'],
                    data['seller_type'], data['publication_date'], data['is_active'],
                    data['district'], data['metro_station'], data['metro_time'],
                    now, now, data['cian_id']
                ))
                
                print(f"   üìù –û–±–Ω–æ–≤–ª–µ–Ω–æ –≤ –±–∞–∑–µ")
                
            else:
                insert_sql = f"""
                    INSERT INTO {self.table_name} 
                    (cian_id, url, title, address, price, price_per_m2, old_price,
                     area_total, area_living, area_kitchen, floor_current, floor_total, 
                     rooms, year_built, building_type, property_category, property_type, description,
                     seller_type, publication_date, is_active, district, metro_station,
                     metro_time, created_at, updated_at, last_checked)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, 
                            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """
                
                self.cursor.execute(insert_sql, (
                    data['cian_id'], data['url'], data['title'], data['address'],
                    data['price'], data['price_per_m2'], data['old_price'],
                    data['area_total'], data['area_living'], data['area_kitchen'],
                    data['floor_current'], data['floor_total'], data['rooms'], data['year_built'],
                    data['building_type'], data['property_category'], data['property_type'], data['description'],
                    data['seller_type'], data['publication_date'], data['is_active'],
                    data['district'], data['metro_station'], data['metro_time'],
                    now, now, now
                ))
                
                print(f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –±–∞–∑—É")
            
            self.conn.commit()
            return True
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –±–∞–∑—ã: {e}")
            import traceback
            traceback.print_exc()
            self.conn.rollback()
            return False
    
    def save_to_price_history(self, cian_id, price, timestamp):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Ü–µ–Ω"""
        try:
            insert_sql = """
                INSERT INTO price_history (cian_id, price, date_recorded, change_type)
                VALUES (%s, %s, %s, %s)
            """
            
            self.cursor.execute(insert_sql, (cian_id, price, timestamp, 'update'))
        except:
            pass
    
    def save_to_file(self, data):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ —Ñ–∞–π–ª"""
        try:
            filename = f"cian_offers_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"\nüíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {filename}")
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ —Ñ–∞–π–ª: {e}")
            return False
    
    def show_stats(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        if not self.conn:
            print("\n‚ùå –ù–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ")
            return
        
        try:
            print("\n" + "="*50)
            print(f"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –¢–ê–ë–õ–ò–¶–´ '{self.table_name}'")
            print("="*50)
            
            self.cursor.execute(f"SELECT COUNT(*) FROM {self.table_name}")
            total = self.cursor.fetchone()[0]
            print(f"–í—Å–µ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {total}")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –¥–æ–º–æ–≤
            self.cursor.execute(f"""
                SELECT building_type, COUNT(*) 
                FROM {self.table_name} 
                WHERE building_type IS NOT NULL AND building_type != ''
                GROUP BY building_type
                ORDER BY COUNT(*) DESC
            """)
            building_types = self.cursor.fetchall()
            print("\nüè† –¢–∏–ø—ã –¥–æ–º–æ–≤ (–Ω–∞–π–¥–µ–Ω–æ/–≤—Å–µ–≥–æ):")
            if building_types:
                found_count = sum(bt[1] for bt in building_types)
                print(f"  –° —Ç–∏–ø–æ–º –¥–æ–º–∞: {found_count} –∏–∑ {total}")
                for bt in building_types:
                    print(f"    {bt[0]}: {bt[1]}")
            else:
                print("  –¢–∏–ø—ã –¥–æ–º–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∏ –≤ –æ–¥–Ω–æ–º –æ–±—ä—è–≤–ª–µ–Ω–∏–∏")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏
            self.cursor.execute(f"""
                SELECT property_category, COUNT(*) 
                FROM {self.table_name} 
                WHERE property_category IS NOT NULL AND property_category != ''
                GROUP BY property_category
                ORDER BY COUNT(*) DESC
            """)
            categories = self.cursor.fetchall()
            print("\nüè¢ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏:")
            if categories:
                for cat in categories:
                    print(f"    {cat[0]}: {cat[1]}")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≥–æ–¥–∞–º –ø–æ—Å—Ç—Ä–æ–π–∫–∏
            self.cursor.execute(f"""
                SELECT COUNT(*) FROM {self.table_name} 
                WHERE year_built IS NOT NULL
            """)
            with_year = self.cursor.fetchone()[0]
            print(f"\nüìÖ –° –≥–æ–¥–æ–º –ø–æ—Å—Ç—Ä–æ–π–∫–∏: {with_year} –∏–∑ {total}")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –º–µ—Ç—Ä–æ
            print("\nüöá –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–µ—Ç—Ä–æ:")
            self.cursor.execute(f"""
                SELECT COUNT(*) FROM {self.table_name} 
                WHERE metro_station IS NOT NULL AND metro_station != ''
            """)
            with_metro = self.cursor.fetchone()[0]
            print(f"  –°–æ —Å—Ç–∞–Ω—Ü–∏–µ–π –º–µ—Ç—Ä–æ: {with_metro} –∏–∑ {total}")
            
            self.cursor.execute(f"""
                SELECT COUNT(*) FROM {self.table_name} 
                WHERE metro_time IS NOT NULL AND metro_time != ''
            """)
            with_metro_time = self.cursor.fetchone()[0]
            print(f"  –° –≤—Ä–µ–º–µ–Ω–µ–º –¥–æ –º–µ—Ç—Ä–æ: {with_metro_time} –∏–∑ {total}")
            
            # –ü—Ä–∏–º–µ—Ä—ã —Å –º–µ—Ç—Ä–æ
            print("\nüìã –ü—Ä–∏–º–µ—Ä—ã –æ–±—ä—è–≤–ª–µ–Ω–∏–π —Å –º–µ—Ç—Ä–æ:")
            self.cursor.execute(f"""
                SELECT cian_id, metro_station, metro_time, building_type, property_category, year_built
                FROM {self.table_name} 
                WHERE metro_station IS NOT NULL AND metro_station != ''
                ORDER BY created_at DESC 
                LIMIT 5
            """)
            examples = self.cursor.fetchall()
            for ex in examples:
                metro_info = f"–ú–µ—Ç—Ä–æ: {ex[1]}"
                if ex[2]:
                    metro_info += f" ({ex[2]})"
                building_info = f", –¢–∏–ø –¥–æ–º–∞: {ex[3]}" if ex[3] else ""
                category_info = f", –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {ex[4]}" if ex[4] else ""
                year_info = f", –ì–æ–¥: {ex[5]}" if ex[5] else ""
                print(f"  ID: {ex[0]}, {metro_info}{building_info}{category_info}{year_info}")
            
            print("="*50)
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
    
    def run_parsing(self):
        """–ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        urls = [
            "https://spb.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=2&room1=1",
            "https://spb.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=2&room2=1"
        ]
        
        all_data = []
        parsed_count = 0
        
        for url in urls[:1]:
            print(f"\nüåê –ü–∞—Ä—Å–∏–º: {url}")
            
            offers = self.parse_search_page(url)
            
            if not offers:
                print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
                continue
            
            for i, offer in enumerate(offers[:3]):  # –ü–∞—Ä—Å–∏–º —Ç–æ–ª—å–∫–æ 3 –¥–ª—è —Ç–µ—Å—Ç–∞
                print(f"\n[{i+1}/{min(3, len(offers))}]")
                
                data = self.parse_offer(offer)
                
                if data:
                    if self.conn:
                        self.save_to_database(data)
                    
                    all_data.append(data)
                    parsed_count += 1
                
                time.sleep(2)
        
        return all_data, parsed_count
    
    def run(self):
        """–ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞"""
        print("="*60)
        print("–ü–ê–†–°–ï–† –¶–ò–ê–ù –î–õ–Ø –¢–ê–ë–õ–ò–¶–´ cian_offers")
        print("="*60)
        
        if not self.setup_browser():
            return
        
        use_db = input("\n–°–æ—Ö—Ä–∞–Ω—è—Ç—å –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö? (y/n): ").lower() == 'y'
        
        if use_db:
            if not self.setup_database():
                print("\n‚ö†Ô∏è –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
                use_db = False
        
        all_data, parsed_count = self.run_parsing()
        
        if all_data:
            self.save_to_file(all_data)
        
        if use_db:
            self.show_stats()
        
        print(f"\n‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print(f"üìà –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {parsed_count} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
        
        if use_db:
            print("\nüí° –û—Ç–∫—Ä–æ–π—Ç–µ DBeaver –∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:")
            print(f"   SELECT cian_id, building_type, property_category, year_built, metro_station, metro_time FROM {self.table_name} ORDER BY created_at DESC;")
        
        print("\n" + "="*60)
    
    def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ"""
        try:
            if self.driver:
                self.driver.quit()
                print("‚úÖ –ë—Ä–∞—É–∑–µ—Ä –∑–∞–∫—Ä—ã—Ç")
        except:
            pass
        
        try:
            if self.cursor:
                self.cursor.close()
            if self.conn:
                self.conn.close()
                print("‚úÖ –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–π –∑–∞–∫—Ä—ã—Ç–æ")
        except:
            pass

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = CianParser()
    
    try:
        parser.run()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {str(e)}")
        import traceback
        traceback.print_exc()
    finally:
        parser.close()
    
    input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤—ã—Ö–æ–¥–∞...")

if __name__ == "__main__":
    try:
        import selenium
        import bs4
    except ImportError:
        print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: pip install selenium beautifulsoup4")
        sys.exit(1)
    
    main()