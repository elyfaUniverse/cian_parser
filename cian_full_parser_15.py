# cian_parser_final.py
import time
import re
import json
import sys
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup

class CianParser:
    def __init__(self):
        """–ü–∞—Ä—Å–µ—Ä –¶–ò–ê–ù –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã cian_offers"""
        self.driver = None
        self.conn = None
        self.cursor = None
        self.table_name = "cian_offers"
    
    def setup_browser(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –±—Ä–∞—É–∑–µ—Ä–∞"""
        print("\nüåê –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –±—Ä–∞—É–∑–µ—Ä–∞...")
        
        options = Options()
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
        
        try:
            self.driver = webdriver.Chrome(options=options)
            print("‚úÖ –ë—Ä–∞—É–∑–µ—Ä –∑–∞–ø—É—â–µ–Ω")
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –±—Ä–∞—É–∑–µ—Ä–∞: {e}")
            return False
    
    def setup_database(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ"""
        print("\nüîå –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö...")
        
        db_config = {
            'host': 'localhost',
            'port': '5432',
            'database': 'cian_parser_2',
            'user': 'postgres',
            'password': 'Mamba123'
        }
        
        try:
            import psycopg2
            
            conn = psycopg2.connect(
                host=db_config['host'],
                port=db_config['port'],
                database=db_config['database'],
                user=db_config['user'],
                password=db_config['password'],
                client_encoding='UTF8'
            )
            
            self.conn = conn
            self.cursor = self.conn.cursor()
            
            print(f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ –±–∞–∑–µ: {db_config['database']}")
            print(f"üìã –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–∞–±–ª–∏—Ü—É: {self.table_name}")
            
            self.check_table_structure()
            
            return True
            
        except ImportError:
            print("‚ùå –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install psycopg2-binary")
            return False
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {str(e)}")
            return False
    
    def check_table_structure(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–∞–±–ª–∏—Ü—ã"""
        try:
            self.cursor.execute(f"""
                SELECT EXISTS (
                    SELECT FROM information_schema.tables 
                    WHERE table_name = '{self.table_name}'
                )
            """)
            
            table_exists = self.cursor.fetchone()[0]
            
            if not table_exists:
                print(f"‚ùå –¢–∞–±–ª–∏—Ü–∞ '{self.table_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
                return False
            
            self.cursor.execute(f"""
                SELECT column_name, data_type, is_nullable
                FROM information_schema.columns
                WHERE table_name = '{self.table_name}'
                ORDER BY ordinal_position
            """)
            
            columns = self.cursor.fetchall()
            print(f"\nüìã –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã '{self.table_name}':")
            for col in columns:
                print(f"  {col[0]}: {col[1]}")
            
            required_columns = ['cian_id', 'url', 'price', 'title', 'area_total']
            actual_columns = [col[0] for col in columns]
            
            missing = [col for col in required_columns if col not in actual_columns]
            if missing:
                print(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Å—Ç–æ–ª–±—Ü—ã: {missing}")
                return False
            
            print("‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã –ø–æ–¥—Ö–æ–¥–∏—Ç")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã: {e}")
            return False
    
    def parse_search_page(self, url):
        """–ü–∞—Ä—Å–∏–Ω–≥ –ø–æ–∏—Å–∫–æ–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        print(f"\nüîç –ü–æ–∏—Å–∫ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {url}")
        
        try:
            self.driver.get(url)
            time.sleep(3)
            
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)
            
            links = self.driver.find_elements(By.TAG_NAME, 'a')
            offers = []
            
            for link in links:
                try:
                    href = link.get_attribute('href')
                    if href and 'cian.ru/sale/flat' in href:
                        match = re.search(r'/(\d+)/?$', href)
                        if match:
                            offer_id = match.group(1)
                            if not any(o['id'] == offer_id for o in offers):
                                offers.append({
                                    'id': offer_id,
                                    'url': href
                                })
                except:
                    continue
            
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {len(offers)}")
            return offers[:10]
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {e}")
            return []
    
    def parse_offer(self, offer):
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è"""
        try:
            print(f"\nüìÑ –ü–∞—Ä—Å–∏–º ID: {offer['id']}")
            
            self.driver.get(offer['url'])
            time.sleep(2)
            
            # –°–æ–∑–¥–∞–µ–º BeautifulSoup –æ–±—ä–µ–∫—Ç –¥–ª—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞
            soup = BeautifulSoup(self.driver.page_source, 'html.parser')
            
            data = {
                'cian_id': offer['id'],
                'url': offer['url'],
                'title': self.get_element_text('h1') or self.get_element_text('[data-name="OfferTitle"]'),
                'address': self.get_element_text('[data-name="GeoLabel"]') or self.get_element_text('[data-name="AddressContainer"]'),
                'price': self.extract_price(),
                'price_per_m2': self.extract_price_per_m2(),
                'old_price': self.extract_old_price(),
                'area_total': self.extract_area_from_title() or self.extract_area_from_description(),
                'area_living': self.extract_living_area(),
                'area_kitchen': self.extract_kitchen_area(),
                'floor_current': self.extract_current_floor(),
                'floor_total': self.extract_total_floors(),
                'rooms': self.extract_rooms(),
                'year_built': self.extract_year_built_improved(soup),
                'building_type': self.extract_building_type_improved(soup),
                'property_type': self.extract_property_type(),
                'description': None,
                'seller_type': self.extract_seller_type(),
                'publication_date': datetime.now().strftime('%Y-%m-%d'),
                'is_active': True,
                'district': self.extract_district(),
                'metro_station': self.extract_metro_station_improved(soup),
                'metro_time': self.extract_metro_time_improved(soup),
                'last_checked': datetime.now()
            }
            
            # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if data['title']:
                print(f"   üìù {data['title'][:50]}...")
            if data['price']:
                print(f"   üí∞ {data['price']:,} ‚ÇΩ")
            if data['address']:
                print(f"   üìç {data['address'][:40]}...")
            if data['building_type']:
                print(f"   üè† –¢–∏–ø –¥–æ–º–∞: {data['building_type']}")
            if data['property_type']:
                print(f"   üè¢ –¢–∏–ø –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏: {data['property_type']}")
            if data['year_built']:
                print(f"   üìÖ –ì–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏: {data['year_built']}")
            if data['metro_station']:
                metro_info = f"üöá –ú–µ—Ç—Ä–æ: {data['metro_station']}"
                if data['metro_time']:
                    metro_info += f" ({data['metro_time']})"
                print(f"   {metro_info}")
            else:
                print(f"   üöá –ú–µ—Ç—Ä–æ: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ (–≤—Ä–µ–º—è: {data['metro_time'] if data['metro_time'] else '–Ω–µ—Ç'})")
            if data['floor_current']:
                print(f"   üè¢ –≠—Ç–∞–∂: {data['floor_current']}/{data['floor_total'] if data['floor_total'] else '?'}")
            
            return data
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            import traceback
            traceback.print_exc()
            return None

    
    def get_element_text(self, selector):
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç —ç–ª–µ–º–µ–Ω—Ç–∞"""
        try:
            element = self.driver.find_element(By.CSS_SELECTOR, selector)
            return element.text.strip()
        except:
            return None
    
    def extract_price(self):
        """–ò–∑–≤–ª–µ—á—å —Ü–µ–Ω—É"""
        try:
            # –û—Å–Ω–æ–≤–Ω–∞—è —Ü–µ–Ω–∞
            price_selectors = [
                '[data-mark="MainPrice"]',
                '[data-name="PriceInfo"] span',
                'span[class*="price"]',
                'div[class*="price"]'
            ]
            
            for selector in price_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for elem in elements:
                        text = elem.text
                        # –£–±–∏—Ä–∞–µ–º –≤–∞–ª—é—Ç—É –∏ –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
                        price_text = re.sub(r'[^\d\s]', '', text)
                        numbers = re.findall(r'[\d\s]+', price_text)
                        if numbers:
                            price_str = numbers[0].replace(' ', '').replace('\xa0', '')
                            if price_str.isdigit() and len(price_str) > 3:
                                return int(price_str)
                except:
                    continue
            
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥
            page_text = self.driver.page_source
            match = re.search(r'"price":\s*(\d+)', page_text)
            if match:
                return int(match.group(1))
                
        except:
            pass
        return None
    
    def extract_old_price(self):
        """–ò–∑–≤–ª–µ—á—å —Å—Ç–∞—Ä—É—é —Ü–µ–Ω—É"""
        try:
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-mark="OldPrice"]')
            for elem in elements:
                text = elem.text
                numbers = re.findall(r'[\d\s]+', text)
                if numbers:
                    price_str = numbers[0].replace(' ', '').replace('\xa0', '')
                    if price_str.isdigit() and len(price_str) > 3:
                        return int(price_str)
        except:
            pass
        return None
    
    def extract_price_per_m2(self):
        """–ò–∑–≤–ª–µ—á—å —Ü–µ–Ω—É –∑–∞ –º2"""
        try:
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-mark="PricePerMeter"]')
            for elem in elements:
                text = elem.text
                numbers = re.findall(r'[\d\s]+', text)
                if numbers:
                    price_str = numbers[0].replace(' ', '').replace('\xa0', '')
                    if price_str.isdigit():
                        return int(price_str)
        except:
            pass
        return None
    
    def extract_area_from_title(self):
        """–ò–∑–≤–ª–µ—á—å –ø–ª–æ—â–∞–¥—å –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
        try:
            title = self.get_element_text('h1') or ''
            match = re.search(r'(\d+[,.]?\d*)\s*–º¬≤', title)
            if match:
                return float(match.group(1).replace(',', '.'))
        except:
            pass
        return None
    
    def extract_area_from_description(self):
        """–ò–∑–≤–ª–µ—á—å –ø–ª–æ—â–∞–¥—å –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è"""
        try:
            # –ò—â–µ–º –≤ –±–ª–æ–∫–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-name="Features"]')
            for elem in elements:
                text = elem.text
                match = re.search(r'(\d+[,.]?\d*)\s*–º¬≤', text)
                if match:
                    return float(match.group(1).replace(',', '.'))
            
            # –ò—â–µ–º –≤ –æ–±—â–µ–º —Ç–µ–∫—Å—Ç–µ
            page_text = self.driver.page_source
            match = re.search(r'"totalArea":\s*(\d+\.?\d*)', page_text)
            if match:
                return float(match.group(1))
        except:
            pass
        return None
    
    def extract_living_area(self):
        """–ò–∑–≤–ª–µ—á—å –∂–∏–ª—É—é –ø–ª–æ—â–∞–¥—å"""
        try:
            # –ò—â–µ–º –≤ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞—Ö
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-name="Features"]')
            for elem in elements:
                text = elem.text
                match = re.search(r'–ñ–∏–ª–∞—è –ø–ª–æ—â–∞–¥—å[:\s]*(\d+[,.]?\d*)\s*–º¬≤', text, re.IGNORECASE)
                if match:
                    return float(match.group(1).replace(',', '.'))
            
            page_text = self.driver.page_source
            match = re.search(r'"livingArea":\s*(\d+\.?\d*)', page_text)
            if match:
                return float(match.group(1))
        except:
            pass
        return None
    
    def extract_kitchen_area(self):
        """–ò–∑–≤–ª–µ—á—å –ø–ª–æ—â–∞–¥—å –∫—É—Ö–Ω–∏"""
        try:
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-name="Features"]')
            for elem in elements:
                text = elem.text
                match = re.search(r'–ü–ª–æ—â–∞–¥—å –∫—É—Ö–Ω–∏[:\s]*(\d+[,.]?\d*)\s*–º¬≤', text, re.IGNORECASE)
                if match:
                    return float(match.group(1).replace(',', '.'))
            
            page_text = self.driver.page_source
            match = re.search(r'"kitchenArea":\s*(\d+\.?\d*)', page_text)
            if match:
                return float(match.group(1))
        except:
            pass
        return None
    
    def extract_rooms(self):
        """–ò–∑–≤–ª–µ—á—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç"""
        try:
            title = self.get_element_text('h1') or ''
            title_lower = title.lower()
            
            if '—Å—Ç—É–¥–∏—è' in title_lower or '–∞–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç' in title_lower:
                return 0
            
            match = re.search(r'(\d+)[-\s]*(?:–∫–æ–º–Ω|–∫–æ–º–Ω–∞—Ç)', title_lower)
            if match:
                return int(match.group(1))
            
            if '1-–∫–æ–º–Ω' in title_lower or '1 –∫–æ–º–Ω' in title_lower:
                return 1
            elif '2-–∫–æ–º–Ω' in title_lower or '2 –∫–æ–º–Ω' in title_lower:
                return 2
            elif '3-–∫–æ–º–Ω' in title_lower or '3 –∫–æ–º–Ω' in title_lower:
                return 3
            elif '4-–∫–æ–º–Ω' in title_lower or '4 –∫–æ–º–Ω' in title_lower:
                return 4
        except:
            pass
        return None
    
    def extract_current_floor(self):
        """–ò–∑–≤–ª–µ—á—å —Ç–µ–∫—É—â–∏–π —ç—Ç–∞–∂"""
        try:
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-name="Features"]')
            for elem in elements:
                text = elem.text
                match = re.search(r'(\d+)\s*—ç—Ç–∞–∂', text)
                if match:
                    return int(match.group(1))
                
                match = re.search(r'(\d+)\s*/\s*(\d+)', text)
                if match and '—ç—Ç–∞–∂' in text.lower():
                    return int(match.group(1))
            
            page_text = self.driver.page_source
            match = re.search(r'"floor":\s*"(\d+)"', page_text)
            if match:
                return int(match.group(1))
            
            match = re.search(r'"floorNumber":\s*(\d+)', page_text)
            if match:
                return int(match.group(1))
                
        except:
            pass
        return None
    
    def extract_total_floors(self):
        """–ò–∑–≤–ª–µ—á—å –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç—Ç–∞–∂–µ–π"""
        try:
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-name="Features"]')
            for elem in elements:
                text = elem.text
                match = re.search(r'–∏–∑\s*(\d+)', text)
                if match:
                    return int(match.group(1))
                
                match = re.search(r'(\d+)\s*/\s*(\d+)', text)
                if match and '—ç—Ç–∞–∂' in text.lower():
                    return int(match.group(2))
            
            page_text = self.driver.page_source
            match = re.search(r'"floorsCount":\s*(\d+)', page_text)
            if match:
                return int(match.group(1))
            
            match = re.search(r'"totalFloors":\s*(\d+)', page_text)
            if match:
                return int(match.group(1))
                
        except:
            pass
        return None
    
    def extract_year_built_improved(self, soup):
        """–ò–∑–≤–ª–µ—á—å –≥–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏ - –£–õ–£–ß–®–ï–ù–ù–´–ô –ú–ï–¢–û–î"""
        try:
            # 1. –ü–æ–∏—Å–∫ –≤ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞—Ö (—Å–∞–º—ã–π –Ω–∞–¥–µ–∂–Ω—ã–π —Å–ø–æ—Å–æ–±)
            page_text = soup.get_text()
            
            # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –≥–æ–¥–∞
            patterns = [
                r'–ì–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏[:\s]*(\d{4})',
                r'–ü–æ—Å—Ç—Ä–æ–µ–Ω –≤[:\s]*(\d{4})',
                r'–°–¥–∞–Ω –≤[:\s]*(\d{4})',
                r'–î–æ–º\s+(\d{4})\s+–≥–æ–¥–∞',
                r'(\d{4})\s+–≥–æ–¥\s+–ø–æ—Å—Ç—Ä–æ–π–∫–∏',
                r'–≥–æ–¥[:\s]*(\d{4})',
                r'built.*?(\d{4})',
                r'construction.*?(\d{4})',
            ]
            
            for pattern in patterns:
                match = re.search(pattern, page_text, re.IGNORECASE)
                if match:
                    year = int(match.group(1))
                    if 1800 <= year <= datetime.now().year:
                        return year
            
            # 2. –ü–æ–∏—Å–∫ –≤ JSON-LD –¥–∞–Ω–Ω—ã—Ö
            json_ld = soup.find('script', type='application/ld+json')
            if json_ld and json_ld.string:
                try:
                    data = json.loads(json_ld.string)
                    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø–æ–ª—è
                    for field in ['yearBuilt', 'dateBuilt', 'constructionDate', 'buildDate']:
                        if field in data:
                            year_str = str(data[field])
                            match = re.search(r'(\d{4})', year_str)
                            if match:
                                year = int(match.group(1))
                                if 1800 <= year <= datetime.now().year:
                                    return year
                except:
                    pass
            
            # 3. –ü–æ–∏—Å–∫ –≤ —Å–∫—Ä–∏–ø—Ç–∞—Ö —Å –¥–∞–Ω–Ω—ã–º–∏
            scripts = soup.find_all('script')
            for script in scripts:
                if script.string:
                    # –ò—â–µ–º –≥–æ–¥ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
                    script_patterns = [
                        r'"year":\s*"(\d{4})"',
                        r'"year":\s*(\d{4})',
                        r'"buildYear":\s*"(\d{4})"',
                        r'"buildYear":\s*(\d{4})',
                        r'"constructionYear":\s*"(\d{4})"',
                        r'"constructionYear":\s*(\d{4})',
                        r'"yearBuilt":\s*"(\d{4})"',
                        r'"yearBuilt":\s*(\d{4})',
                    ]
                    
                    for pattern in script_patterns:
                        match = re.search(pattern, script.string)
                        if match:
                            year = int(match.group(1))
                            if 1800 <= year <= datetime.now().year:
                                return year
            
            # 4. –ü–æ–∏—Å–∫ –ø–æ —Å–µ—Ä–∏–∏ –¥–æ–º–∞ (–∫–æ—Å–≤–µ–Ω–Ω—ã–π —Å–ø–æ—Å–æ–±)
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –¥–æ–º–∞ –∏ –ø—Ä–∏–º–µ—Ä–Ω—ã–π –≥–æ–¥ –ø–æ —Å–µ—Ä–∏–∏
            building_type = self.extract_building_type_improved(soup)
            if building_type:
                # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–µ –≥–æ–¥—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥–æ–º–æ–≤ –≤ –°–ü–±
                if building_type == '—Ö—Ä—É—â–µ–≤—Å–∫–∏–π':
                    return 1960  # –ü—Ä–∏–º–µ—Ä–Ω–æ 1950-1970
                elif building_type == '–±—Ä–µ–∂–Ω–µ–≤—Å–∫–∏–π':
                    return 1975  # –ü—Ä–∏–º–µ—Ä–Ω–æ 1960-1980
                elif building_type == '—Å—Ç–∞–ª–∏–Ω—Å–∫–∏–π':
                    return 1950  # –ü—Ä–∏–º–µ—Ä–Ω–æ 1930-1955
                elif building_type == '–ø–∞–Ω–µ–ª—å–Ω—ã–π':
                    # –î–ª—è –ø–∞–Ω–µ–ª—å–Ω—ã—Ö –¥–æ–º–æ–≤ –≤ –ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–æ–º —Ä–∞–π–æ–Ω–µ
                    if '–≥—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π' in page_text.lower() or '–∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫' in page_text.lower():
                        return 1970  # –¢–∏–ø–∏—á–Ω—ã–µ –≥–æ–¥—ã –¥–ª—è —ç—Ç–æ–≥–æ —Ä–∞–π–æ–Ω–∞
            
            # 5. –ü–æ–∏—Å–∫ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏
            description = soup.find('div', {'data-name': 'Description'})
            if description:
                desc_text = description.get_text()
                match = re.search(r'(\d{4})\s+–≥–æ–¥', desc_text)
                if match:
                    year = int(match.group(1))
                    if 1800 <= year <= datetime.now().year:
                        return year
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –≥–æ–¥–∞ –ø–æ—Å—Ç—Ä–æ–π–∫–∏: {e}")
        return None
    
    def extract_building_type_improved(self, soup):
        """–ò–∑–≤–ª–µ—á—å —Ç–∏–ø –¥–æ–º–∞ - –ü–†–û–°–¢–û–ô –ò –≠–§–§–ï–ö–¢–ò–í–ù–´–ô –ú–ï–¢–û–î"""
        try:
            # 1. –ò—â–µ–º –≤ –±–ª–æ–∫–∞—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ (—Å–∞–º—ã–π –Ω–∞–¥–µ–∂–Ω—ã–π —Å–ø–æ—Å–æ–±)
            # –ù–∞ –¶–ò–ê–ù —Ç–∏–ø –¥–æ–º–∞ –æ–±—ã—á–Ω–æ –≤ –±–ª–æ–∫–∞—Ö —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏
            feature_blocks = soup.find_all(['div', 'li'], class_=lambda x: x and any(
                word in str(x).lower() for word in ['feature', 'param', 'item', 'characteristic']
            ))
            
            for block in feature_blocks:
                text = block.get_text().lower()
                # –ò—â–µ–º —Ñ—Ä–∞–∑—É "–¢–∏–ø –¥–æ–º–∞" –∏–ª–∏ "–ú–∞—Ç–µ—Ä–∏–∞–ª —Å—Ç–µ–Ω"
                if '—Ç–∏–ø –¥–æ–º–∞' in text or '–º–∞—Ç–µ—Ä–∏–∞–ª —Å—Ç–µ–Ω' in text or '—Ç–∏–ø –∑–¥–∞–Ω–∏—è' in text:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ –¥–≤–æ–µ—Ç–æ—á–∏—è –∏–ª–∏ —Ç–∏—Ä–µ
                    value = text.split(':')[-1].split('-')[-1].strip()
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
                    if any(word in value for word in ['–ø–∞–Ω–µ–ª—å', '–ø–∞–Ω–µ–ª—å–Ω—ã–π']):
                        return '–ø–∞–Ω–µ–ª—å–Ω—ã–π'
                    elif any(word in value for word in ['–∫–∏—Ä–ø–∏—á', '–∫–∏—Ä–ø–∏—á–Ω—ã–π']):
                        return '–∫–∏—Ä–ø–∏—á–Ω—ã–π'
                    elif any(word in value for word in ['–º–æ–Ω–æ–ª–∏—Ç', '–º–æ–Ω–æ–ª–∏—Ç–Ω—ã–π']):
                        return '–º–æ–Ω–æ–ª–∏—Ç–Ω—ã–π'
                    elif any(word in value for word in ['–±–ª–æ–∫', '–±–ª–æ—á–Ω—ã–π']):
                        return '–±–ª–æ—á–Ω—ã–π'
                    elif any(word in value for word in ['–¥–µ—Ä–µ–≤–æ', '–¥–µ—Ä–µ–≤—è–Ω–Ω—ã–π']):
                        return '–¥–µ—Ä–µ–≤—è–Ω–Ω—ã–π'
                    elif any(word in value for word in ['—Ö—Ä—É—â', '—Ö—Ä—É—â–µ–≤']):
                        return '—Ö—Ä—É—â–µ–≤—Å–∫–∏–π'
                    elif any(word in value for word in ['—Å—Ç–∞–ª–∏–Ω']):
                        return '—Å—Ç–∞–ª–∏–Ω—Å–∫–∏–π'
                    elif any(word in value for word in ['–±—Ä–µ–∂–Ω–µ–≤']):
                        return '–±—Ä–µ–∂–Ω–µ–≤—Å–∫–∏–π'
            
            # 2. –ò—â–µ–º –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (JSON-LD –∏–ª–∏ —Å–∫—Ä–∏–ø—Ç–∞—Ö)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º JSON-LD
            json_ld = soup.find('script', type='application/ld+json')
            if json_ld and json_ld.string:
                try:
                    data = json.loads(json_ld.string)
                    # –ò—â–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–¥–∞–Ω–∏–∏
                    for key, value in data.items():
                        if isinstance(value, str) and '–¥–æ–º' in value.lower():
                            value_lower = value.lower()
                            if '–ø–∞–Ω–µ–ª—å' in value_lower:
                                return '–ø–∞–Ω–µ–ª—å–Ω—ã–π'
                            elif '–∫–∏—Ä–ø–∏—á' in value_lower:
                                return '–∫–∏—Ä–ø–∏—á–Ω—ã–π'
                except:
                    pass
            
            # 3. –ò—â–µ–º –ø–æ –≤—Å–µ–º—É —Ç–µ–∫—Å—Ç—É –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            page_text_lower = soup.get_text().lower()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
            if '–ø–∞–Ω–µ–ª—å–Ω—ã–π –¥–æ–º' in page_text_lower or '–ø–∞–Ω–µ–ª—å' in page_text_lower:
                return '–ø–∞–Ω–µ–ª—å–Ω—ã–π'
            elif '–∫–∏—Ä–ø–∏—á–Ω—ã–π –¥–æ–º' in page_text_lower or '–∫–∏—Ä–ø–∏—á' in page_text_lower:
                return '–∫–∏—Ä–ø–∏—á–Ω—ã–π'
            elif '–º–æ–Ω–æ–ª–∏—Ç–Ω—ã–π –¥–æ–º' in page_text_lower or '–º–æ–Ω–æ–ª–∏—Ç' in page_text_lower:
                return '–º–æ–Ω–æ–ª–∏—Ç–Ω—ã–π'
            elif '–±–ª–æ—á–Ω—ã–π –¥–æ–º' in page_text_lower or '–±–ª–æ—á–Ω—ã–π' in page_text_lower:
                return '–±–ª–æ—á–Ω—ã–π'
            elif '—Ö—Ä—É—â–µ–≤–∫–∞' in page_text_lower or '—Ö—Ä—É—â' in page_text_lower:
                return '—Ö—Ä—É—â–µ–≤—Å–∫–∏–π'
            elif '—Å—Ç–∞–ª–∏–Ω–∫–∞' in page_text_lower or '—Å—Ç–∞–ª–∏–Ω' in page_text_lower:
                return '—Å—Ç–∞–ª–∏–Ω—Å–∫–∏–π'
            
            # 4. –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –ø—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏
            year = self.extract_year_built_improved(soup)
            if year:
                if 1930 <= year <= 1955:
                    return '—Å—Ç–∞–ª–∏–Ω—Å–∫–∏–π'
                elif 1956 <= year <= 1970:
                    return '—Ö—Ä—É—â–µ–≤—Å–∫–∏–π'
                elif 1971 <= year <= 1990:
                    return '–ø–∞–Ω–µ–ª—å–Ω—ã–π'
                elif year > 1990:
                    return '–ø–∞–Ω–µ–ª—å–Ω—ã–π'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–æ–º–æ–≤
            
            return None  # –ù–µ –Ω–∞—à–ª–∏
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Ç–∏–ø–∞ –¥–æ–º–∞: {e}")
            return None

    def extract_property_type(self):
        """–ò–∑–≤–ª–µ—á—å —Ç–∏–ø –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏"""
        try:
            current_url = self.driver.current_url
            if 'newbuilding' in current_url:
                return '–Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞'
            else:
                return '–≤—Ç–æ—Ä–∏—á–∫–∞'
        except:
            return '–≤—Ç–æ—Ä–∏—á–∫–∞'
    
    def extract_seller_type(self):
        """–ò–∑–≤–ª–µ—á—å —Ç–∏–ø –ø—Ä–æ–¥–∞–≤—Ü–∞"""
        try:
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-name="Owner"]')
            for elem in elements:
                text = elem.text.lower()
                if '—Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫' in text or '–≤–ª–∞–¥–µ–ª–µ—Ü' in text:
                    return '—Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫'
                elif '–∞–≥–µ–Ω—Ç—Å—Ç–≤–æ' in text or '—Ä–∏–µ–ª—Ç–æ—Ä' in text:
                    return '–∞–≥–µ–Ω—Ç—Å—Ç–≤–æ'
        except:
            pass
        return None
    
    def extract_district(self):
        """–ò–∑–≤–ª–µ—á—å —Ä–∞–π–æ–Ω"""
        try:
            address = self.get_element_text('[data-name="GeoLabel"]') or self.get_element_text('[data-name="AddressContainer"]')
            if address:
                parts = address.split(',')
                for part in parts:
                    part = part.strip()
                    if '—Ä-–Ω' in part:
                        return part.replace('—Ä-–Ω', '').strip()
                    elif '—Ä–∞–π–æ–Ω' in part:
                        return part.replace('—Ä–∞–π–æ–Ω', '').strip()
                    
                if len(parts) > 1:
                    return parts[1].strip()
        except:
            pass
        return None
    
    def extract_metro_station_improved(self, soup):
        """–ò–∑–≤–ª–µ—á—å —Å—Ç–∞–Ω—Ü–∏—é –º–µ—Ç—Ä–æ - –£–ü–†–û–©–ï–ù–ù–´–ô –ú–ï–¢–û–î"""
        try:
            # 1. –ò—â–µ–º –≤ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö –±–ª–æ–∫–∞—Ö –¶–ò–ê–ù
            metro_selectors = [
                '[data-name="UndergroundStation"]',
                '[data-name="GeoUnderground"]',
                '[class*="underground"]',
                '[class*="metro"]',
                'a[href*="underground"]',
                'a[href*="metro"]',
            ]
            
            for selector in metro_selectors:
                try:
                    elements = soup.select(selector)
                    for elem in elements:
                        text = elem.get_text(strip=True)
                        if text and '–º–µ—Ç—Ä–æ' in text.lower():
                            # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–µ–≥–æ
                            station = re.sub(r'\([^)]+\)', '', text)  # –£–±–∏—Ä–∞–µ–º —Å–∫–æ–±–∫–∏ —Å –≤—Ä–µ–º–µ–Ω–µ–º
                            station = station.replace('–º–µ—Ç—Ä–æ', '').replace('–º.', '').strip()
                            station = re.sub(r'\d+\s*–º–∏–Ω', '', station)  # –£–±–∏—Ä–∞–µ–º –≤—Ä–µ–º—è
                            station = station.strip()
                            
                            if station and 2 < len(station) < 30:
                                return station
                except:
                    continue
            
            # 2. –ò—â–µ–º –ø–æ —Å–ø–∏—Å–∫—É —Å—Ç–∞–Ω—Ü–∏–π –°–ü–±
            stations_spb = [
                '–ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∞—è', '–ì—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π –ø—Ä–æ—Å–ø–µ–∫—Ç', '–î–µ–≤—è—Ç–∫–∏–Ω–æ',
                '–ü–æ–ª–∏—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è', '–ü–ª–æ—â–∞–¥—å –ú—É–∂–µ—Å—Ç–≤–∞', '–õ–µ—Å–Ω–∞—è',
                '–í—ã–±–æ—Ä–≥—Å–∫–∞—è', '–ü–ª–æ—â–∞–¥—å –õ–µ–Ω–∏–Ω–∞', '–ß–µ—Ä–Ω—ã—à–µ–≤—Å–∫–∞—è',
                '–ü–ª–æ—â–∞–¥—å –í–æ—Å—Å—Ç–∞–Ω–∏—è', '–í–ª–∞–¥–∏–º–∏—Ä—Å–∫–∞—è', '–ü—É—à–∫–∏–Ω—Å–∫–∞—è',
                '–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∏–Ω—Å—Ç–∏—Ç—É—Ç', '–ë–∞–ª—Ç–∏–π—Å–∫–∞—è', '–ù–∞—Ä–≤—Å–∫–∞—è',
                '–ö–∏—Ä–æ–≤—Å–∫–∏–π –∑–∞–≤–æ–¥', '–ê–≤—Ç–æ–≤–æ', '–õ–µ–Ω–∏–Ω—Å–∫–∏–π –ø—Ä–æ—Å–ø–µ–∫—Ç',
                '–ü—Ä–æ—Å–ø–µ–∫—Ç –í–µ—Ç–µ—Ä–∞–Ω–æ–≤', '–ü–∞—Ä–∫ –ü–æ–±–µ–¥—ã', '–≠–ª–µ–∫—Ç—Ä–æ—Å–∏–ª–∞',
                '–ú–æ—Å–∫–æ–≤—Å–∫–∞—è', '–ó–≤—ë–∑–¥–Ω–∞—è', '–ö—É–ø—á–∏–Ω–æ',
            ]
            
            page_text = soup.get_text()
            for station in stations_spb:
                if station in page_text:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
                    start = max(0, page_text.find(station) - 50)
                    end = min(len(page_text), page_text.find(station) + 50)
                    context = page_text[start:end].lower()
                    
                    if any(word in context for word in ['–º–µ—Ç—Ä–æ', '—Å—Ç–∞–Ω—Ü–∏—è', '–º.', '—Å—Ç.']):
                        return station
            
            return None
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –º–µ—Ç—Ä–æ: {e}")
            return None

    def extract_metro_time_improved(self, soup):
        """–ò–∑–≤–ª–µ—á—å –≤—Ä–µ–º—è –¥–æ –º–µ—Ç—Ä–æ - –£–õ–£–ß–®–ï–ù–ù–´–ô –ú–ï–¢–û–î"""
        try:
            page_text = soup.get_text()
            
            # 1. –ò—â–µ–º –≤—Ä–µ–º—è —Ä—è–¥–æ–º —Å —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º –º–µ—Ç—Ä–æ
            metro_positions = []
            for match in re.finditer(r'–º–µ—Ç—Ä–æ|—Å—Ç–∞–Ω—Ü–∏—è', page_text, re.IGNORECASE):
                metro_positions.append(match.start())
            
            for pos in metro_positions:
                start = max(0, pos - 100)
                end = min(len(page_text), pos + 100)
                context = page_text[start:end]
                
                time_patterns = [
                    r'(\d+)\s*–º–∏–Ω(?:—É—Ç)?\.?',
                    r'\((\d+)\s*–º–∏–Ω(?:—É—Ç)?\.?\)',
                    r'(\d+)\s*–º–∏–Ω—É—Ç',
                ]
                
                for pattern in time_patterns:
                    match = re.search(pattern, context, re.IGNORECASE)
                    if match:
                        time_str = match.group(1)
                        if time_str.isdigit():
                            time_val = int(time_str)
                            if 1 <= time_val <= 120:
                                return f"{time_val} –º–∏–Ω"
            
            # 2. –ò—â–µ–º –≤ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö –¶–ò–ê–ù
            time_selectors = [
                '[data-name="UndergroundTime"]',
                '[class*="underground-time"]',
                '[class*="metro-time"]',
                '[class*="walk-time"]',
                '[data-name="TransportTime"]',
            ]
            
            for selector in time_selectors:
                try:
                    elements = soup.select(selector)
                    for elem in elements:
                        text = elem.get_text(strip=True)
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã
                        match = re.search(r'(\d+)', text)
                        if match:
                            time_val = int(match.group(1))
                            if 1 <= time_val <= 120:
                                return f"{time_val} –º–∏–Ω"
                except:
                    continue
            
            # 3. –ò—â–µ–º —Ä—è–¥–æ–º —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º —Å—Ç–∞–Ω—Ü–∏–∏ –º–µ—Ç—Ä–æ
            if self.extract_metro_station_improved(soup):
                # –ò—â–µ–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Å—Ç–∞–Ω—Ü–∏–∏ –º–µ—Ç—Ä–æ
                station_pos = page_text.find(self.extract_metro_station_improved(soup))
                if station_pos != -1:
                    # –°–º–æ—Ç—Ä–∏–º —Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ —Å—Ç–∞–Ω—Ü–∏–∏ (100 —Å–∏–º–≤–æ–ª–æ–≤ –≤ –æ–±–µ —Å—Ç–æ—Ä–æ–Ω—ã)
                    start = max(0, station_pos - 100)
                    end = min(len(page_text), station_pos + 100)
                    context = page_text[start:end]
                    
                    # –ò—â–µ–º –≤—Ä–µ–º—è –≤ —ç—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
                    for pattern in time_patterns:
                        match = re.search(pattern, context, re.IGNORECASE)
                        if match:
                            time_str = match.group(1)
                            if time_str.isdigit():
                                time_val = int(time_str)
                                if 1 <= time_val <= 120:
                                    return f"{time_val} –º–∏–Ω"
            
            return None
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–æ –º–µ—Ç—Ä–æ: {e}")
            return None

    def save_to_database(self, data):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –±–∞–∑—É"""
        if not data or not self.conn:
            return False
        
        try:
            self.cursor.execute(
                f"SELECT price FROM {self.table_name} WHERE cian_id = %s",
                (data['cian_id'],)
            )
            
            existing = self.cursor.fetchone()
            now = datetime.now()
            
            if existing:
                old_price = existing[0]
                new_price = data.get('price')
                
                if new_price and new_price != old_price:
                    print(f"   üí± –¶–µ–Ω–∞ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å: {old_price:,} ‚Üí {new_price:,} ‚ÇΩ")
                    self.save_to_price_history(data['cian_id'], new_price, now)
                
                update_sql = f"""
                    UPDATE {self.table_name} SET
                    url = %s, title = %s, address = %s, price = %s, price_per_m2 = %s,
                    old_price = %s, area_total = %s, area_living = %s, area_kitchen = %s,
                    floor_current = %s, floor_total = %s, rooms = %s, year_built = %s,
                    building_type = %s, property_type = %s, description = %s,
                    seller_type = %s, publication_date = %s, is_active = %s,
                    district = %s, metro_station = %s, metro_time = %s,
                    updated_at = %s, last_checked = %s
                    WHERE cian_id = %s
                """
                
                self.cursor.execute(update_sql, (
                    data['url'], data['title'], data['address'],
                    data['price'], data['price_per_m2'],
                    data['old_price'], data['area_total'], data['area_living'], data['area_kitchen'],
                    data['floor_current'], data['floor_total'], data['rooms'], data['year_built'],
                    data['building_type'], data['property_type'], data['description'],
                    data['seller_type'], data['publication_date'], data['is_active'],
                    data['district'], data['metro_station'], data['metro_time'],
                    now, now, data['cian_id']
                ))
                
                print(f"   üìù –û–±–Ω–æ–≤–ª–µ–Ω–æ –≤ –±–∞–∑–µ")
                
            else:
                insert_sql = f"""
                    INSERT INTO {self.table_name} 
                    (cian_id, url, title, address, price, price_per_m2, old_price,
                    area_total, area_living, area_kitchen, floor_current, floor_total, 
                    rooms, year_built, building_type, property_type, description,
                    seller_type, publication_date, is_active, district, metro_station,
                    metro_time, created_at, updated_at, last_checked)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, 
                            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """
                
                self.cursor.execute(insert_sql, (
                    data['cian_id'], data['url'], data['title'], data['address'],
                    data['price'], data['price_per_m2'], data['old_price'],
                    data['area_total'], data['area_living'], data['area_kitchen'],
                    data['floor_current'], data['floor_total'], data['rooms'], data['year_built'],
                    data['building_type'], data['property_type'], data['description'],
                    data['seller_type'], data['publication_date'], data['is_active'],
                    data['district'], data['metro_station'], data['metro_time'],
                    now, now, now
                ))
                
                print(f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –±–∞–∑—É")
            
            self.conn.commit()
            return True
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –±–∞–∑—ã: {e}")
            import traceback
            traceback.print_exc()
            self.conn.rollback()
            return False
    
    def save_to_price_history(self, cian_id, price, timestamp):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Ü–µ–Ω"""
        try:
            insert_sql = """
                INSERT INTO price_history (cian_id, price, date_recorded, change_type)
                VALUES (%s, %s, %s, %s)
            """
            
            self.cursor.execute(insert_sql, (cian_id, price, timestamp, 'update'))
        except:
            pass
    
    def save_to_file(self, data):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ —Ñ–∞–π–ª"""
        try:
            filename = f"cian_offers_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"\nüíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {filename}")
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ —Ñ–∞–π–ª: {e}")
            return False
    
    def show_stats(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        if not self.conn:
            print("\n‚ùå –ù–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ")
            return
        
        try:
            print("\n" + "="*50)
            print(f"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –¢–ê–ë–õ–ò–¶–´ '{self.table_name}'")
            print("="*50)
            
            self.cursor.execute(f"SELECT COUNT(*) FROM {self.table_name}")
            total = self.cursor.fetchone()[0]
            print(f"–í—Å–µ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {total}")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –¥–æ–º–æ–≤
            self.cursor.execute(f"""
                SELECT building_type, COUNT(*) 
                FROM {self.table_name} 
                WHERE building_type IS NOT NULL AND building_type != ''
                GROUP BY building_type
                ORDER BY COUNT(*) DESC
            """)
            building_types = self.cursor.fetchall()
            print("\nüè† –¢–∏–ø—ã –¥–æ–º–æ–≤ (–Ω–∞–π–¥–µ–Ω–æ/–≤—Å–µ–≥–æ):")
            if building_types:
                found_count = sum(bt[1] for bt in building_types)
                print(f"  –° —Ç–∏–ø–æ–º –¥–æ–º–∞: {found_count} –∏–∑ {total}")
                for bt in building_types:
                    print(f"    {bt[0]}: {bt[1]}")
            else:
                print("  –¢–∏–ø—ã –¥–æ–º–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∏ –≤ –æ–¥–Ω–æ–º –æ–±—ä—è–≤–ª–µ–Ω–∏–∏")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏
            self.cursor.execute(f"""
                SELECT property_type, COUNT(*) 
                FROM {self.table_name} 
                WHERE property_type IS NOT NULL AND property_type != ''
                GROUP BY property_type
                ORDER BY COUNT(*) DESC
            """)
            categories = self.cursor.fetchall()
            print("\nüè¢ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏:")
            if categories:
                for cat in categories:
                    print(f"    {cat[0]}: {cat[1]}")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≥–æ–¥–∞–º –ø–æ—Å—Ç—Ä–æ–π–∫–∏
            self.cursor.execute(f"""
                SELECT COUNT(*) FROM {self.table_name} 
                WHERE year_built IS NOT NULL
            """)
            with_year = self.cursor.fetchone()[0]
            print(f"\nüìÖ –° –≥–æ–¥–æ–º –ø–æ—Å—Ç—Ä–æ–π–∫–∏: {with_year} –∏–∑ {total}")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –º–µ—Ç—Ä–æ
            print("\nüöá –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–µ—Ç—Ä–æ:")
            self.cursor.execute(f"""
                SELECT COUNT(*) FROM {self.table_name} 
                WHERE metro_station IS NOT NULL AND metro_station != ''
            """)
            with_metro = self.cursor.fetchone()[0]
            print(f"  –°–æ —Å—Ç–∞–Ω—Ü–∏–µ–π –º–µ—Ç—Ä–æ: {with_metro} –∏–∑ {total}")
            
            self.cursor.execute(f"""
                SELECT COUNT(*) FROM {self.table_name} 
                WHERE metro_time IS NOT NULL AND metro_time != ''
            """)
            with_metro_time = self.cursor.fetchone()[0]
            print(f"  –° –≤—Ä–µ–º–µ–Ω–µ–º –¥–æ –º–µ—Ç—Ä–æ: {with_metro_time} –∏–∑ {total}")
            
            # –ü—Ä–∏–º–µ—Ä—ã —Å –º–µ—Ç—Ä–æ
            print("\nüìã –ü—Ä–∏–º–µ—Ä—ã –æ–±—ä—è–≤–ª–µ–Ω–∏–π —Å –º–µ—Ç—Ä–æ:")
            self.cursor.execute(f"""
                SELECT cian_id, metro_station, metro_time, building_type, property_type, year_built
                FROM {self.table_name} 
                WHERE metro_station IS NOT NULL AND metro_station != ''
                ORDER BY created_at DESC 
                LIMIT 5
            """)
            examples = self.cursor.fetchall()
            for ex in examples:
                metro_info = f"–ú–µ—Ç—Ä–æ: {ex[1]}"
                if ex[2]:
                    metro_info += f" ({ex[2]})"
                building_info = f", –¢–∏–ø –¥–æ–º–∞: {ex[3]}" if ex[3] else ""
                category_info = f", –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {ex[4]}" if ex[4] else ""
                year_info = f", –ì–æ–¥: {ex[5]}" if ex[5] else ""
                print(f"  ID: {ex[0]}, {metro_info}{building_info}{category_info}{year_info}")
            
            print("="*50)
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")

    def run_parsing(self):
        """–ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        urls = [
            "https://spb.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=2&room1=1",
            "https://spb.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=2&room2=1"
        ]
        
        all_data = []
        parsed_count = 0
        
        for url in urls[:1]:
            print(f"\nüåê –ü–∞—Ä—Å–∏–º: {url}")
            
            offers = self.parse_search_page(url)
            
            if not offers:
                print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
                continue
            
            for i, offer in enumerate(offers[:3]):  # –ü–∞—Ä—Å–∏–º —Ç–æ–ª—å–∫–æ 3 –¥–ª—è —Ç–µ—Å—Ç–∞
                print(f"\n[{i+1}/{min(3, len(offers))}]")
                
                data = self.parse_offer(offer)
                
                if data:
                    if self.conn:
                        self.save_to_database(data)
                    
                    all_data.append(data)
                    parsed_count += 1
                
                time.sleep(2)
        
        return all_data, parsed_count
    
    def run(self):
        """–ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞"""
        print("="*60)
        print("–ü–ê–†–°–ï–† –¶–ò–ê–ù –î–õ–Ø –¢–ê–ë–õ–ò–¶–´ cian_offers")
        print("="*60)
        
        if not self.setup_browser():
            return
        
        use_db = input("\n–°–æ—Ö—Ä–∞–Ω—è—Ç—å –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö? (y/n): ").lower() == 'y'
        
        if use_db:
            if not self.setup_database():
                print("\n‚ö†Ô∏è –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
                use_db = False
        
        all_data, parsed_count = self.run_parsing()
        
        if all_data:
            self.save_to_file(all_data)
        
        if use_db:
            self.show_stats()
        
        print(f"\n‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print(f"üìà –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {parsed_count} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
        
        if use_db:
            print("\nüí° –û—Ç–∫—Ä–æ–π—Ç–µ DBeaver –∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:")
            print(f"   SELECT cian_id, building_type, property_type, year_built, metro_station, metro_time FROM {self.table_name} ORDER BY created_at DESC;")
        
        print("\n" + "="*60)
    
    def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ"""
        try:
            if self.driver:
                self.driver.quit()
                print("‚úÖ –ë—Ä–∞—É–∑–µ—Ä –∑–∞–∫—Ä—ã—Ç")
        except:
            pass
        
        try:
            if self.cursor:
                self.cursor.close()
            if self.conn:
                self.conn.close()
                print("‚úÖ –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–π –∑–∞–∫—Ä—ã—Ç–æ")
        except:
            pass

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = CianParser()
    
    try:
        parser.run()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {str(e)}")
        import traceback
        traceback.print_exc()
    finally:
        parser.close()
    
    input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤—ã—Ö–æ–¥–∞...")

if __name__ == "__main__":
    try:
        import selenium
        import bs4
    except ImportError:
        print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: pip install selenium beautifulsoup4")
        sys.exit(1)
    
    main()