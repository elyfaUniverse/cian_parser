# cian_parser_final.py
import time
import re
import json
import sys
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup

class CianParser:
    def __init__(self):
        """–ü–∞—Ä—Å–µ—Ä –¶–ò–ê–ù –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã cian_offers"""
        self.driver = None
        self.conn = None
        self.cursor = None
        self.table_name = "cian_offers"
    
    def setup_browser(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –±—Ä–∞—É–∑–µ—Ä–∞"""
        print("\nüåê –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –±—Ä–∞—É–∑–µ—Ä–∞...")
        
        options = Options()
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
        
        try:
            self.driver = webdriver.Chrome(options=options)
            print("‚úÖ –ë—Ä–∞—É–∑–µ—Ä –∑–∞–ø—É—â–µ–Ω")
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –±—Ä–∞—É–∑–µ—Ä–∞: {e}")
            return False
    
    def setup_database(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ"""
        print("\nüîå –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö...")
        
        db_config = {
            'host': 'localhost',
            'port': '5432',
            'database': 'cian_parser_2',
            'user': 'postgres',
            'password': 'Mamba123'
        }
        
        try:
            import psycopg2
            
            conn = psycopg2.connect(
                host=db_config['host'],
                port=db_config['port'],
                database=db_config['database'],
                user=db_config['user'],
                password=db_config['password'],
                client_encoding='UTF8'
            )
            
            self.conn = conn
            self.cursor = self.conn.cursor()
            
            print(f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ –±–∞–∑–µ: {db_config['database']}")
            print(f"üìã –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–∞–±–ª–∏—Ü—É: {self.table_name}")
            
            self.check_table_structure()
            
            return True
            
        except ImportError:
            print("‚ùå –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install psycopg2-binary")
            return False
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {str(e)}")
            return False
    
    def check_table_structure(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–∞–±–ª–∏—Ü—ã"""
        try:
            self.cursor.execute(f"""
                SELECT EXISTS (
                    SELECT FROM information_schema.tables 
                    WHERE table_name = '{self.table_name}'
                )
            """)
            
            table_exists = self.cursor.fetchone()[0]
            
            if not table_exists:
                print(f"‚ùå –¢–∞–±–ª–∏—Ü–∞ '{self.table_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
                return False
            
            self.cursor.execute(f"""
                SELECT column_name, data_type, is_nullable
                FROM information_schema.columns
                WHERE table_name = '{self.table_name}'
                ORDER BY ordinal_position
            """)
            
            columns = self.cursor.fetchall()
            print(f"\nüìã –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã '{self.table_name}':")
            for col in columns:
                print(f"  {col[0]}: {col[1]}")
            
            required_columns = ['cian_id', 'url', 'price', 'title', 'area_total']
            actual_columns = [col[0] for col in columns]
            
            missing = [col for col in required_columns if col not in actual_columns]
            if missing:
                print(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Å—Ç–æ–ª–±—Ü—ã: {missing}")
                return False
            
            print("‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã –ø–æ–¥—Ö–æ–¥–∏—Ç")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã: {e}")
            return False
    
    def parse_search_page(self, url):
        """–ü–∞—Ä—Å–∏–Ω–≥ –ø–æ–∏—Å–∫–æ–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        print(f"\nüîç –ü–æ–∏—Å–∫ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {url}")
        
        try:
            self.driver.get(url)
            time.sleep(3)
            
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)
            
            links = self.driver.find_elements(By.TAG_NAME, 'a')
            offers = []
            
            for link in links:
                try:
                    href = link.get_attribute('href')
                    if href and 'cian.ru/sale/flat' in href:
                        match = re.search(r'/(\d+)/?$', href)
                        if match:
                            offer_id = match.group(1)
                            if not any(o['id'] == offer_id for o in offers):
                                offers.append({
                                    'id': offer_id,
                                    'url': href
                                })
                except:
                    continue
            
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {len(offers)}")
            return offers[:10]
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {e}")
            return []
    
    def parse_offer(self, offer):
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è"""
        try:
            print(f"\nüìÑ –ü–∞—Ä—Å–∏–º ID: {offer['id']}")
            
            self.driver.get(offer['url'])
            time.sleep(2)
            
            # –î–ï–ë–ê–ì: –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            with open(f"debug_{offer['id']}.html", "w", encoding="utf-8") as f:
                f.write(self.driver.page_source)
            print(f"   üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω HTML –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏: debug_{offer['id']}.html")
            
            # –°–æ–∑–¥–∞–µ–º BeautifulSoup –æ–±—ä–µ–∫—Ç –¥–ª—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞
            soup = BeautifulSoup(self.driver.page_source, 'html.parser')
            
            data = {
                'cian_id': offer['id'],
                'url': offer['url'],
                'title': self.get_element_text('h1') or self.get_element_text('[data-name="OfferTitle"]'),
                'address': self.get_element_text('[data-name="GeoLabel"]') or self.get_element_text('[data-name="AddressContainer"]'),
                'price': self.extract_price(),
                'price_per_m2': self.extract_price_per_m2(),
                'old_price': self.extract_old_price(),
                'area_total': self.extract_area_from_title() or self.extract_area_from_description(),
                'area_living': self.extract_living_area(),
                'area_kitchen': self.extract_kitchen_area(),
                'floor_current': self.extract_current_floor(),
                'floor_total': self.extract_total_floors(),
                'rooms': self.extract_rooms(),
                'year_built': self.extract_year_built(),
                'building_type': self.extract_building_type(soup),  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ —Å BeautifulSoup
                'property_category': self.extract_property_category(soup),  # –ù–æ–≤—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                'property_type': self.extract_property_type(),
                'description': None,
                'seller_type': self.extract_seller_type(),
                'publication_date': datetime.now().strftime('%Y-%m-%d'),
                'is_active': True,
                'district': self.extract_district(),
                'metro_station': self.extract_metro_station(soup),  # –£–ª—É—á—à–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥
                'metro_time': self.extract_metro_time(soup),  # –£–ª—É—á—à–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥
                'last_checked': datetime.now()
            }
            
            # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if data['title']:
                print(f"   üìù {data['title'][:50]}...")
            if data['price']:
                print(f"   üí∞ {data['price']:,} ‚ÇΩ")
            if data['address']:
                print(f"   üìç {data['address'][:40]}...")
            if data['building_type']:
                print(f"   üè† –¢–∏–ø –¥–æ–º–∞: {data['building_type']}")
            else:
                print(f"   üè† –¢–∏–ø –¥–æ–º–∞: –Ω–µ –Ω–∞–π–¥–µ–Ω")
            if data['property_category']:
                print(f"   üè¢ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {data['property_category']}")
            if data['metro_station']:
                metro_info = f"üöá –ú–µ—Ç—Ä–æ: {data['metro_station']}"
                if data['metro_time']:
                    metro_info += f" ({data['metro_time']})"
                else:
                    metro_info += f" (–≤—Ä–µ–º—è –Ω–µ –Ω–∞–π–¥–µ–Ω–æ)"
                print(f"   {metro_info}")
            else:
                print(f"   üöá –ú–µ—Ç—Ä–æ: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            if data['floor_current']:
                print(f"   üè¢ –≠—Ç–∞–∂: {data['floor_current']}/{data['floor_total'] if data['floor_total'] else '?'}")
            
            return data
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def get_element_text(self, selector):
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç —ç–ª–µ–º–µ–Ω—Ç–∞"""
        try:
            element = self.driver.find_element(By.CSS_SELECTOR, selector)
            return element.text.strip()
        except:
            return None
    
    def extract_price(self):
        """–ò–∑–≤–ª–µ—á—å —Ü–µ–Ω—É"""
        try:
            # –û—Å–Ω–æ–≤–Ω–∞—è —Ü–µ–Ω–∞
            price_selectors = [
                '[data-mark="MainPrice"]',
                '[data-name="PriceInfo"] span',
                'span[class*="price"]',
                'div[class*="price"]'
            ]
            
            for selector in price_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for elem in elements:
                        text = elem.text
                        # –£–±–∏—Ä–∞–µ–º –≤–∞–ª—é—Ç—É –∏ –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
                        price_text = re.sub(r'[^\d\s]', '', text)
                        numbers = re.findall(r'[\d\s]+', price_text)
                        if numbers:
                            price_str = numbers[0].replace(' ', '').replace('\xa0', '')
                            if price_str.isdigit() and len(price_str) > 3:
                                return int(price_str)
                except:
                    continue
            
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥
            page_text = self.driver.page_source
            match = re.search(r'"price":\s*(\d+)', page_text)
            if match:
                return int(match.group(1))
                
        except:
            pass
        return None
    
    def extract_old_price(self):
        """–ò–∑–≤–ª–µ—á—å —Å—Ç–∞—Ä—É—é —Ü–µ–Ω—É"""
        try:
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-mark="OldPrice"]')
            for elem in elements:
                text = elem.text
                numbers = re.findall(r'[\d\s]+', text)
                if numbers:
                    price_str = numbers[0].replace(' ', '').replace('\xa0', '')
                    if price_str.isdigit() and len(price_str) > 3:
                        return int(price_str)
        except:
            pass
        return None
    
    def extract_price_per_m2(self):
        """–ò–∑–≤–ª–µ—á—å —Ü–µ–Ω—É –∑–∞ –º2"""
        try:
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-mark="PricePerMeter"]')
            for elem in elements:
                text = elem.text
                numbers = re.findall(r'[\d\s]+', text)
                if numbers:
                    price_str = numbers[0].replace(' ', '').replace('\xa0', '')
                    if price_str.isdigit():
                        return int(price_str)
        except:
            pass
        return None
    
    def extract_area_from_title(self):
        """–ò–∑–≤–ª–µ—á—å –ø–ª–æ—â–∞–¥—å –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
        try:
            title = self.get_element_text('h1') or ''
            match = re.search(r'(\d+[,.]?\d*)\s*–º¬≤', title)
            if match:
                return float(match.group(1).replace(',', '.'))
        except:
            pass
        return None
    
    def extract_area_from_description(self):
        """–ò–∑–≤–ª–µ—á—å –ø–ª–æ—â–∞–¥—å –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è"""
        try:
            # –ò—â–µ–º –≤ –±–ª–æ–∫–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-name="Features"]')
            for elem in elements:
                text = elem.text
                match = re.search(r'(\d+[,.]?\d*)\s*–º¬≤', text)
                if match:
                    return float(match.group(1).replace(',', '.'))
            
            # –ò—â–µ–º –≤ –æ–±—â–µ–º —Ç–µ–∫—Å—Ç–µ
            page_text = self.driver.page_source
            match = re.search(r'"totalArea":\s*(\d+\.?\d*)', page_text)
            if match:
                return float(match.group(1))
        except:
            pass
        return None
    
    def extract_living_area(self):
        """–ò–∑–≤–ª–µ—á—å –∂–∏–ª—É—é –ø–ª–æ—â–∞–¥—å"""
        try:
            # –ò—â–µ–º –≤ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞—Ö
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-name="Features"]')
            for elem in elements:
                text = elem.text
                match = re.search(r'–ñ–∏–ª–∞—è –ø–ª–æ—â–∞–¥—å[:\s]*(\d+[,.]?\d*)\s*–º¬≤', text, re.IGNORECASE)
                if match:
                    return float(match.group(1).replace(',', '.'))
            
            page_text = self.driver.page_source
            match = re.search(r'"livingArea":\s*(\d+\.?\d*)', page_text)
            if match:
                return float(match.group(1))
        except:
            pass
        return None
    
    def extract_kitchen_area(self):
        """–ò–∑–≤–ª–µ—á—å –ø–ª–æ—â–∞–¥—å –∫—É—Ö–Ω–∏"""
        try:
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-name="Features"]')
            for elem in elements:
                text = elem.text
                match = re.search(r'–ü–ª–æ—â–∞–¥—å –∫—É—Ö–Ω–∏[:\s]*(\d+[,.]?\d*)\s*–º¬≤', text, re.IGNORECASE)
                if match:
                    return float(match.group(1).replace(',', '.'))
            
            page_text = self.driver.page_source
            match = re.search(r'"kitchenArea":\s*(\d+\.?\d*)', page_text)
            if match:
                return float(match.group(1))
        except:
            pass
        return None
    
    def extract_rooms(self):
        """–ò–∑–≤–ª–µ—á—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç"""
        try:
            title = self.get_element_text('h1') or ''
            title_lower = title.lower()
            
            if '—Å—Ç—É–¥–∏—è' in title_lower or '–∞–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç' in title_lower:
                return 0
            
            match = re.search(r'(\d+)[-\s]*(?:–∫–æ–º–Ω|–∫–æ–º–Ω–∞—Ç)', title_lower)
            if match:
                return int(match.group(1))
            
            if '1-–∫–æ–º–Ω' in title_lower or '1 –∫–æ–º–Ω' in title_lower:
                return 1
            elif '2-–∫–æ–º–Ω' in title_lower or '2 –∫–æ–º–Ω' in title_lower:
                return 2
            elif '3-–∫–æ–º–Ω' in title_lower or '3 –∫–æ–º–Ω' in title_lower:
                return 3
            elif '4-–∫–æ–º–Ω' in title_lower or '4 –∫–æ–º–Ω' in title_lower:
                return 4
        except:
            pass
        return None
    
    def extract_current_floor(self):
        """–ò–∑–≤–ª–µ—á—å —Ç–µ–∫—É—â–∏–π —ç—Ç–∞–∂"""
        try:
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-name="Features"]')
            for elem in elements:
                text = elem.text
                match = re.search(r'(\d+)\s*—ç—Ç–∞–∂', text)
                if match:
                    return int(match.group(1))
                
                match = re.search(r'(\d+)\s*/\s*(\d+)', text)
                if match and '—ç—Ç–∞–∂' in text.lower():
                    return int(match.group(1))
            
            page_text = self.driver.page_source
            match = re.search(r'"floor":\s*"(\d+)"', page_text)
            if match:
                return int(match.group(1))
            
            match = re.search(r'"floorNumber":\s*(\d+)', page_text)
            if match:
                return int(match.group(1))
                
        except:
            pass
        return None
    
    def extract_total_floors(self):
        """–ò–∑–≤–ª–µ—á—å –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç—Ç–∞–∂–µ–π"""
        try:
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-name="Features"]')
            for elem in elements:
                text = elem.text
                match = re.search(r'–∏–∑\s*(\d+)', text)
                if match:
                    return int(match.group(1))
                
                match = re.search(r'(\d+)\s*/\s*(\d+)', text)
                if match and '—ç—Ç–∞–∂' in text.lower():
                    return int(match.group(2))
            
            page_text = self.driver.page_source
            match = re.search(r'"floorsCount":\s*(\d+)', page_text)
            if match:
                return int(match.group(1))
            
            match = re.search(r'"totalFloors":\s*(\d+)', page_text)
            if match:
                return int(match.group(1))
                
        except:
            pass
        return None
    
    def extract_year_built(self):
        """–ò–∑–≤–ª–µ—á—å –≥–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏"""
        try:
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-name="Features"]')
            for elem in elements:
                text = elem.text
                match = re.search(r'–ì–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏[:\s]*(\d{4})', text, re.IGNORECASE)
                if match:
                    return int(match.group(1))
            
            page_text = self.driver.page_source
            match = re.search(r'"year":\s*(\d{4})', page_text)
            if match:
                return int(match.group(1))
        except:
            pass
        return None
    
    def extract_building_type(self, soup):
        """–ò–∑–≤–ª–µ—á—å —Ç–∏–ø –¥–æ–º–∞ - –£–õ–£–ß–®–ï–ù–ù–´–ô –ú–ï–¢–û–î —Å BeautifulSoup"""
        try:
            # 1. –ü–æ–∏—Å–∫ –≤ JSON-LD –¥–∞–Ω–Ω—ã—Ö
            json_ld = soup.find('script', type='application/ld+json')
            if json_ld and json_ld.string:
                try:
                    data = json.loads(json_ld.string)
                    if 'description' in data:
                        desc = data['description'].lower()
                        if '–ø–∞–Ω–µ–ª—å–Ω—ã–π' in desc or '–ø–∞–Ω–µ–ª—å' in desc:
                            return '–ø–∞–Ω–µ–ª—å–Ω—ã–π'
                        elif '–∫–∏—Ä–ø–∏—á–Ω—ã–π' in desc or '–∫–∏—Ä–ø–∏—á' in desc:
                            return '–∫–∏—Ä–ø–∏—á–Ω—ã–π'
                        elif '–º–æ–Ω–æ–ª–∏—Ç–Ω—ã–π' in desc or '–º–æ–Ω–æ–ª–∏—Ç' in desc:
                            return '–º–æ–Ω–æ–ª–∏—Ç–Ω—ã–π'
                        elif '–±–ª–æ—á–Ω—ã–π' in desc or '–±–ª–æ–∫' in desc:
                            return '–±–ª–æ—á–Ω—ã–π'
                except:
                    pass
            
            # 2. –ü–æ–∏—Å–∫ –≤ —Å–∫—Ä–∏–ø—Ç–∞—Ö —Å JSON
            scripts = soup.find_all('script')
            for script in scripts:
                if script.string:
                    # –ò—â–µ–º houseType –≤ JSON
                    match = re.search(r'"houseType":\s*"([^"]+)"', script.string, re.IGNORECASE)
                    if match:
                        house_type = match.group(1).lower()
                        if 'panel' in house_type or '–ø–∞–Ω–µ–ª—å' in house_type:
                            return '–ø–∞–Ω–µ–ª—å–Ω—ã–π'
                        elif 'brick' in house_type or '–∫–∏—Ä–ø–∏—á' in house_type:
                            return '–∫–∏—Ä–ø–∏—á–Ω—ã–π'
                        elif 'monolithic' in house_type or '–º–æ–Ω–æ–ª–∏—Ç' in house_type:
                            return '–º–æ–Ω–æ–ª–∏—Ç–Ω—ã–π'
                        elif 'block' in house_type or '–±–ª–æ–∫' in house_type:
                            return '–±–ª–æ—á–Ω—ã–π'
                        elif 'wood' in house_type or '–¥–µ—Ä–µ–≤–æ' in house_type:
                            return '–¥–µ—Ä–µ–≤—è–Ω–Ω—ã–π'
            
            # 3. –ü–æ–∏—Å–∫ –≤ —Ç–µ–∫—Å—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            page_text = soup.get_text().lower()
            
            # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≤ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞—Ö
            features_sections = soup.find_all(['div', 'section'], class_=lambda x: x and any(keyword in str(x) for keyword in ['features', 'characteristics', 'specs']))
            
            for section in features_sections:
                section_text = section.get_text().lower()
                lines = section_text.split('\n')
                for line in lines:
                    if '—Ç–∏–ø –¥–æ–º–∞' in line or '—Ç–∏–ø –∑–¥–∞–Ω–∏—è' in line:
                        if '–ø–∞–Ω–µ–ª—å–Ω—ã–π' in line:
                            return '–ø–∞–Ω–µ–ª—å–Ω—ã–π'
                        elif '–∫–∏—Ä–ø–∏—á–Ω—ã–π' in line:
                            return '–∫–∏—Ä–ø–∏—á–Ω—ã–π'
                        elif '–º–æ–Ω–æ–ª–∏—Ç–Ω—ã–π' in line:
                            return '–º–æ–Ω–æ–ª–∏—Ç–Ω—ã–π'
                        elif '–±–ª–æ—á–Ω—ã–π' in line:
                            return '–±–ª–æ—á–Ω—ã–π'
                        elif '–¥–µ—Ä–µ–≤—è–Ω–Ω—ã–π' in line:
                            return '–¥–µ—Ä–µ–≤—è–Ω–Ω—ã–π'
            
            # 4. –ü–æ–∏—Å–∫ –ø–æ —Å–µ—Ä–∏–∏ –¥–æ–º–∞
            series_patterns = [
                r'—Å–µ—Ä–∏—è\s*[:\s]*([^\s,]+)',
                r'([–ê-–Ø–∞-—è]\s*[-‚Äî]?\s*\d+\s*[–ê-–Ø–∞-—è]?)',
                r'(–ü\s*[-‚Äî]?\s*\d+)',
                r'(–ò\s*[-‚Äî]?\s*\d+)',
                r'(1\s*[-‚Äî]?\s*[–ê-–Ø–∞-—è])'
            ]
            
            for pattern in series_patterns:
                match = re.search(pattern, page_text, re.IGNORECASE)
                if match:
                    series = match.group(1).upper()
                    if any(s in series for s in ['–ü', '–ü–ê–ù–ï–õ–¨', '–ü-', '–ü–ê']):
                        return '–ø–∞–Ω–µ–ª—å–Ω—ã–π'
                    elif any(s in series for s in ['–ö', '–ö–ò–†–ü', '–ö-']):
                        return '–∫–∏—Ä–ø–∏—á–Ω—ã–π'
                    elif any(s in series for s in ['–ú', '–ú–û–ù–û–õ–ò–¢', '–ú-']):
                        return '–º–æ–Ω–æ–ª–∏—Ç–Ω—ã–π'
            
            # 5. –ü—Ä—è–º–æ–π –ø–æ–∏—Å–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
            keywords = {
                '–ø–∞–Ω–µ–ª—å–Ω—ã–π': ['–ø–∞–Ω–µ–ª—å–Ω—ã–π', '–ø–∞–Ω–µ–ª—å', '–ø–∞–Ω–µ–ª—å–Ω–æ–µ'],
                '–∫–∏—Ä–ø–∏—á–Ω—ã–π': ['–∫–∏—Ä–ø–∏—á–Ω—ã–π', '–∫–∏—Ä–ø–∏—á', '–∫–∏—Ä–ø–∏—á–Ω–æ–µ'],
                '–º–æ–Ω–æ–ª–∏—Ç–Ω—ã–π': ['–º–æ–Ω–æ–ª–∏—Ç–Ω—ã–π', '–º–æ–Ω–æ–ª–∏—Ç', '–º–æ–Ω–æ–ª–∏—Ç–Ω–æ–µ'],
                '–±–ª–æ—á–Ω—ã–π': ['–±–ª–æ—á–Ω—ã–π', '–±–ª–æ–∫', '–±–ª–æ—á–Ω–æ–µ'],
                '–¥–µ—Ä–µ–≤—è–Ω–Ω—ã–π': ['–¥–µ—Ä–µ–≤—è–Ω–Ω—ã–π', '–¥–µ—Ä–µ–≤–æ', '–¥–µ—Ä–µ–≤—è–Ω–Ω–æ–µ'],
                '—Å—Ç–∞–ª–∏–Ω—Å–∫–∏–π': ['—Å—Ç–∞–ª–∏–Ω—Å–∫–∏–π', '—Å—Ç–∞–ª–∏–Ω–∫–∞'],
                '—Ö—Ä—É—â–µ–≤—Å–∫–∏–π': ['—Ö—Ä—É—â–µ–≤—Å–∫–∏–π', '—Ö—Ä—É—â–µ–≤–∫–∞'],
                '–±—Ä–µ–∂–Ω–µ–≤—Å–∫–∏–π': ['–±—Ä–µ–∂–Ω–µ–≤—Å–∫–∏–π', '–±—Ä–µ–∂–Ω–µ–≤–∫–∞']
            }
            
            for house_type, word_list in keywords.items():
                for word in word_list:
                    if word in page_text:
                        return house_type
            
            # 6. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –≥–æ–¥—É –ø–æ—Å—Ç—Ä–æ–π–∫–∏ (–∫–æ—Å–≤–µ–Ω–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫)
            year_match = re.search(r'–≥–æ–¥[:\s]*(\d{4})', page_text)
            if year_match:
                year = int(year_match.group(1))
                if year >= 1990:
                    # –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–æ–º–æ–≤ - –ø–∞–Ω–µ–ª—å–Ω—ã–µ –∏–ª–∏ –º–æ–Ω–æ–ª–∏—Ç–Ω—ã–µ
                    return '–ø–∞–Ω–µ–ª—å–Ω—ã–π'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–æ–º–æ–≤
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Ç–∏–ø–∞ –¥–æ–º–∞: {e}")
        return None
    
    def extract_property_category(self, soup):
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏: –≤—Ç–æ—Ä–∏—á–∫–∞ –∏–ª–∏ –Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞"""
        try:
            page_text = soup.get_text().lower()
            
            # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ–¥ —Å–¥–∞—á–∏
            year_patterns = [
                r'—Å–¥–∞—á–∞.*?(\d{4})',
                r'–≥–æ–¥.*?—Å–¥–∞—á–∏.*?(\d{4})',
                r'(\d{4})\s*–≥–æ–¥.*?—Å–¥–∞—á–∏',
                r'–∫–≤–∞—Ä—Ç–∏—Ä–∞.*?—Å–¥–∞–µ—Ç—Å—è.*?(\d{4})',
                r'–≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å.*?(\d{4})'
            ]
            
            for pattern in year_patterns:
                match = re.search(pattern, page_text, re.IGNORECASE)
                if match:
                    year = int(match.group(1))
                    if year >= datetime.now().year or year >= 2023:  # –ë—É–¥—É—â–∏–π –≥–æ–¥ –∏–ª–∏ –Ω–µ–¥–∞–≤–Ω–∏–π
                        return '–Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞'
            
            # 2. –ò—â–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –Ω–æ–≤–æ—Å—Ç—Ä–æ–µ–∫
            new_building_keywords = [
                '–Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞', '–Ω–æ–≤—ã–π –¥–æ–º', '–Ω–æ–≤—ã–π –∫–æ–º–ø–ª–µ–∫—Å', '—Å—Ç—Ä–æ–π–∫–∞',
                '—Å–¥–∞–µ—Ç—Å—è –≤', '–≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å', '–∑–∞—Å–µ–ª–µ–Ω–∏–µ —Å', '—Å—Ä–æ–∫ —Å–¥–∞—á–∏',
                '–ø–µ—Ä–≤–∏—á–∫–∞', '–ø–µ—Ä–≤–∏—á–Ω—ã–π —Ä—ã–Ω–æ–∫', '–æ—Ç –∑–∞—Å—Ç—Ä–æ–π—â–∏–∫–∞'
            ]
            
            for keyword in new_building_keywords:
                if keyword in page_text:
                    return '–Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞'
            
            # 3. –ò—â–µ–º –≤ JSON-LD
            json_ld = soup.find('script', type='application/ld+json')
            if json_ld and json_ld.string:
                try:
                    data = json.loads(json_ld.string)
                    if 'description' in data:
                        desc = data['description'].lower()
                        if any(keyword in desc for keyword in new_building_keywords):
                            return '–Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞'
                except:
                    pass
            
            # 4. –ò—â–µ–º –≤ —Å–∫—Ä–∏–ø—Ç–∞—Ö
            scripts = soup.find_all('script')
            for script in scripts:
                if script.string:
                    # –ò—â–µ–º realEstateType
                    match = re.search(r'"realEstateType":\s*"([^"]+)"', script.string, re.IGNORECASE)
                    if match:
                        estate_type = match.group(1).lower()
                        if 'new' in estate_type or '–Ω–æ–≤–æ—Å—Ç—Ä–æ–π' in estate_type:
                            return '–Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞'
                        elif 'secondary' in estate_type or '–≤—Ç–æ—Ä–∏—á' in estate_type:
                            return '–≤—Ç–æ—Ä–∏—á–∫–∞'
            
            # 5. –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏
            year_match = re.search(r'–≥–æ–¥.*?–ø–æ—Å—Ç—Ä–æ–π–∫–∏[:\s]*(\d{4})', page_text)
            if year_match:
                year = int(year_match.group(1))
                if year >= datetime.now().year - 5:  # –ü–æ—Å—Ç—Ä–æ–π–∫–∏ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 5 –ª–µ—Ç
                    return '–Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞'
            
            # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—á–∏—Ç–∞–µ–º –≤—Ç–æ—Ä–∏—á–∫–æ–π
            return '–≤—Ç–æ—Ä–∏—á–∫–∞'
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {e}")
            return '–≤—Ç–æ—Ä–∏—á–∫–∞'
    
    def extract_property_type(self):
        """–ò–∑–≤–ª–µ—á—å —Ç–∏–ø –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏"""
        try:
            current_url = self.driver.current_url
            if 'newbuilding' in current_url:
                return '–Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞'
            else:
                return '–≤—Ç–æ—Ä–∏—á–∫–∞'
        except:
            return '–≤—Ç–æ—Ä–∏—á–∫–∞'
    
    def extract_seller_type(self):
        """–ò–∑–≤–ª–µ—á—å —Ç–∏–ø –ø—Ä–æ–¥–∞–≤—Ü–∞"""
        try:
            elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-name="Owner"]')
            for elem in elements:
                text = elem.text.lower()
                if '—Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫' in text or '–≤–ª–∞–¥–µ–ª–µ—Ü' in text:
                    return '—Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫'
                elif '–∞–≥–µ–Ω—Ç—Å—Ç–≤–æ' in text or '—Ä–∏–µ–ª—Ç–æ—Ä' in text:
                    return '–∞–≥–µ–Ω—Ç—Å—Ç–≤–æ'
        except:
            pass
        return None
    
    def extract_district(self):
        """–ò–∑–≤–ª–µ—á—å —Ä–∞–π–æ–Ω"""
        try:
            address = self.get_element_text('[data-name="GeoLabel"]') or self.get_element_text('[data-name="AddressContainer"]')
            if address:
                parts = address.split(',')
                for part in parts:
                    part = part.strip()
                    if '—Ä-–Ω' in part:
                        return part.replace('—Ä-–Ω', '').strip()
                    elif '—Ä–∞–π–æ–Ω' in part:
                        return part.replace('—Ä–∞–π–æ–Ω', '').strip()
                    
                if len(parts) > 1:
                    return parts[1].strip()
        except:
            pass
        return None
    
    def extract_metro_station(self, soup):
        """–ò–∑–≤–ª–µ—á—å —Å—Ç–∞–Ω—Ü–∏—é –º–µ—Ç—Ä–æ - –£–õ–£–ß–®–ï–ù–ù–´–ô –ú–ï–¢–û–î —Å BeautifulSoup"""
        try:
            # 1. –ò—â–µ–º –≤ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö –¶–ò–ê–ù
            metro_selectors = [
                {'data-name': 'UndergroundStation'},
                {'class': lambda x: x and ('underground' in x.lower() or 'metro' in x.lower())},
                {'href': lambda x: x and 'underground' in x}
            ]
            
            for selector in metro_selectors:
                elements = soup.find_all('a', selector)
                for elem in elements:
                    text = elem.get_text(strip=True)
                    if text and len(text) < 50:
                        # –£–±–∏—Ä–∞–µ–º –≤—Ä–µ–º—è –¥–æ –º–µ—Ç—Ä–æ
                        station = re.sub(r'\(\d+\s*–º–∏–Ω\)', '', text)
                        station = re.sub(r'\d+\s*–º–∏–Ω', '', station)
                        station = station.replace('–º–µ—Ç—Ä–æ', '').strip()
                        if station and station not in ['', '–º']:
                            return station
            
            # 2. –ò—â–µ–º –≤ JSON-LD
            json_ld = soup.find('script', type='application/ld+json')
            if json_ld and json_ld.string:
                try:
                    data = json.loads(json_ld.string)
                    if 'description' in data:
                        desc = data['description']
                        # –ò—â–µ–º —Å—Ç–∞–Ω—Ü–∏–∏ –º–µ—Ç—Ä–æ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏
                        stations_spb = [
                            '–ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∞—è', '–ü–æ–ª–∏—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è', '–õ–µ—Å–Ω–∞—è', '–í—ã–±–æ—Ä–≥—Å–∫–∞—è',
                            '–ü–ª–æ—â–∞–¥—å –õ–µ–Ω–∏–Ω–∞', '–ß–µ—Ä–Ω—ã—à–µ–≤—Å–∫–∞—è', '–ü–ª–æ—â–∞–¥—å –í–æ—Å—Å—Ç–∞–Ω–∏—è',
                            '–í–ª–∞–¥–∏–º–∏—Ä—Å–∫–∞—è', '–ü—É—à–∫–∏–Ω—Å–∫–∞—è', '–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∏–Ω—Å—Ç–∏—Ç—É—Ç',
                            '–ë–∞–ª—Ç–∏–π—Å–∫–∞—è', '–ù–∞—Ä–≤—Å–∫–∞—è', '–ö–∏—Ä–æ–≤—Å–∫–∏–π –∑–∞–≤–æ–¥', '–ê–≤—Ç–æ–≤–æ',
                            '–õ–µ–Ω–∏–Ω—Å–∫–∏–π –ø—Ä–æ—Å–ø–µ–∫—Ç', '–ü—Ä–æ—Å–ø–µ–∫—Ç –í–µ—Ç–µ—Ä–∞–Ω–æ–≤', '–ü–∞—Ä–∫ –ü–æ–±–µ–¥—ã',
                            '–≠–ª–µ–∫—Ç—Ä–æ—Å–∏–ª–∞', '–ú–æ—Å–∫–æ–≤—Å–∫–∞—è', '–ó–≤—ë–∑–¥–Ω–∞—è', '–ö—É–ø—á–∏–Ω–æ',
                            '–î–µ–≤—è—Ç–∫–∏–Ω–æ', '–ì—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π –ø—Ä–æ—Å–ø–µ–∫—Ç', '–ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∞—è',
                            '–ü–æ–ª–∏—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è', '–ü–ª–æ—â–∞–¥—å –ú—É–∂–µ—Å—Ç–≤–∞', '–ü–µ—Ç—Ä–æ–≥—Ä–∞–¥—Å–∫–∞—è',
                            '–ì–æ—Ä—å–∫–æ–≤—Å–∫–∞—è', '–ù–µ–≤—Å–∫–∏–π –ø—Ä–æ—Å–ø–µ–∫—Ç', '–°–µ–Ω–Ω–∞—è –ø–ª–æ—â–∞–¥—å',
                            '–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∏–Ω—Å—Ç–∏—Ç—É—Ç', '–§—Ä—É–Ω–∑–µ–Ω—Å–∫–∞—è', '–ú–æ—Å–∫–æ–≤—Å–∫–∏–µ –≤–æ—Ä–æ—Ç–∞',
                            '–≠–ª–µ–∫—Ç—Ä–æ—Å–∏–ª–∞', '–ü–∞—Ä–∫ –ü–æ–±–µ–¥—ã', '–ú–æ—Å–∫–æ–≤—Å–∫–∞—è', '–ó–≤—ë–∑–¥–Ω–∞—è',
                            '–ö—É–ø—á–∏–Ω–æ', '–õ–∞–¥–æ–∂—Å–∫–∞—è', '–ü—Ä–æ—Å–ø–µ–∫—Ç –ë–æ–ª—å—à–µ–≤–∏–∫–æ–≤', '–£–ª–∏—Ü–∞ –î—ã–±–µ–Ω–∫–æ'
                        ]
                        
                        for station in stations_spb:
                            if station in desc:
                                return station
                except:
                    pass
            
            # 3. –ò—â–µ–º –ø–æ —Ç–µ–∫—Å—Ç—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            page_text = soup.get_text()
            stations_spb = [
                '–ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∞—è', '–ü–æ–ª–∏—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è', '–õ–µ—Å–Ω–∞—è', '–í—ã–±–æ—Ä–≥—Å–∫–∞—è',
                '–ü–ª–æ—â–∞–¥—å –õ–µ–Ω–∏–Ω–∞', '–ß–µ—Ä–Ω—ã—à–µ–≤—Å–∫–∞—è', '–ü–ª–æ—â–∞–¥—å –í–æ—Å—Å—Ç–∞–Ω–∏—è'
            ]
            
            for station in stations_spb:
                if station in page_text:
                    return station
            
            # 4. –ò—â–µ–º –≤ –±–ª–æ–∫–µ "–ë–ª–∏–∂–∞–π—à–µ–µ –º–µ—Ç—Ä–æ"
            for elem in soup.find_all(['div', 'p', 'span']):
                text = elem.get_text(strip=True)
                if '–±–ª–∏–∂–∞–π—à–µ–µ –º–µ—Ç—Ä–æ' in text.lower() or '—Å—Ç–∞–Ω—Ü–∏—è –º–µ—Ç—Ä–æ' in text.lower():
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞–Ω—Ü–∏–∏
                    lines = text.split('\n')
                    for line in lines:
                        line = line.strip()
                        if line and '–º–µ—Ç—Ä–æ' not in line.lower() and '–±–ª–∏–∂–∞–π—à–µ–µ' not in line.lower():
                            station = re.sub(r'\(\d+\s*–º–∏–Ω\)', '', line)
                            station = re.sub(r'\d+\s*–º–∏–Ω', '', station)
                            station = station.replace('–º–µ—Ç—Ä–æ', '').strip()
                            if station:
                                return station
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –º–µ—Ç—Ä–æ: {e}")
        return None
    
    def extract_metro_time(self, soup):
        """–ò–∑–≤–ª–µ—á—å –≤—Ä–µ–º—è –¥–æ –º–µ—Ç—Ä–æ - –£–õ–£–ß–®–ï–ù–ù–´–ô –ú–ï–¢–û–î"""
        try:
            page_text = soup.get_text()
            
            # 1. –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤—Ä–µ–º–µ–Ω–∏ –≤ —Ç–µ–∫—Å—Ç–µ
            patterns = [
                r'\((\d+)\s*–º–∏–Ω\.?\)',  # (10 –º–∏–Ω)
                r'(\d+)\s*–º–∏–Ω\.?\s*(?:–¥–æ –º–µ—Ç—Ä–æ|–ø–µ—à–∫–æ–º|—Ö–æ–¥—å–±—ã)',  # 10 –º–∏–Ω –¥–æ –º–µ—Ç—Ä–æ
                r'–¥–æ –º–µ—Ç—Ä–æ\s*(\d+)\s*–º–∏–Ω\.?',  # –¥–æ –º–µ—Ç—Ä–æ 10 –º–∏–Ω
                r'–ø–µ—à–∫–æ–º\s*(\d+)\s*–º–∏–Ω\.?',  # –ø–µ—à–∫–æ–º 10 –º–∏–Ω
                r'(\d+)\s*–º–∏–Ω—É—Ç\s*(?:–¥–æ –º–µ—Ç—Ä–æ|–ø–µ—à–∫–æ–º)',  # 10 –º–∏–Ω—É—Ç –¥–æ –º–µ—Ç—Ä–æ
                r'(\d+)-–º–∏–Ω—É—Ç–Ω–∞—è\s+—Ö–æ–¥—å–±–∞',  # 10-–º–∏–Ω—É—Ç–Ω–∞—è —Ö–æ–¥—å–±–∞
                r'(\d+)\s*–º–∏–Ω\.?\s*–æ—Ç\s*–º–µ—Ç—Ä–æ',  # 10 –º–∏–Ω –æ—Ç –º–µ—Ç—Ä–æ
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, page_text, re.IGNORECASE)
                for match in matches:
                    if str(match).isdigit() and 1 <= int(match) <= 120:
                        return f"{match} –º–∏–Ω"
            
            # 2. –ò—â–µ–º –≤ JSON –¥–∞–Ω–Ω—ã—Ö
            scripts = soup.find_all('script')
            for script in scripts:
                if script.string:
                    # –ò—â–µ–º timeToMetro
                    time_match = re.search(r'"timeToMetro":\s*(\d+)', script.string)
                    if time_match:
                        minutes = time_match.group(1)
                        if 1 <= int(minutes) <= 120:
                            return f"{minutes} –º–∏–Ω"
            
            # 3. –ò—â–µ–º –≤ –≤–∏–¥–∏–º—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö –æ–∫–æ–ª–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –º–µ—Ç—Ä–æ
            metro_elements = soup.find_all(['div', 'span', 'p'], 
                                          class_=lambda x: x and ('metro' in str(x).lower() or 'underground' in str(x).lower()))
            
            for elem in metro_elements:
                text = elem.get_text()
                time_match = re.search(r'(\d+)\s*–º–∏–Ω', text)
                if time_match:
                    return f"{time_match.group(1)} –º–∏–Ω"
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–æ –º–µ—Ç—Ä–æ: {e}")
        return None
    
    def save_to_database(self, data):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –±–∞–∑—É"""
        if not data or not self.conn:
            return False
        
        try:
            self.cursor.execute(
                f"SELECT price FROM {self.table_name} WHERE cian_id = %s",
                (data['cian_id'],)
            )
            
            existing = self.cursor.fetchone()
            now = datetime.now()
            
            if existing:
                old_price = existing[0]
                new_price = data.get('price')
                
                if new_price and new_price != old_price:
                    print(f"   üí± –¶–µ–Ω–∞ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å: {old_price:,} ‚Üí {new_price:,} ‚ÇΩ")
                    self.save_to_price_history(data['cian_id'], new_price, now)
                
                update_sql = f"""
                    UPDATE {self.table_name} SET
                    url = %s, title = %s, address = %s, price = %s, price_per_m2 = %s,
                    old_price = %s, area_total = %s, area_living = %s, area_kitchen = %s,
                    floor_current = %s, floor_total = %s, rooms = %s, year_built = %s,
                    building_type = %s, property_category = %s, property_type = %s, description = %s,
                    seller_type = %s, publication_date = %s, is_active = %s,
                    district = %s, metro_station = %s, metro_time = %s,
                    updated_at = %s, last_checked = %s
                    WHERE cian_id = %s
                """
                
                self.cursor.execute(update_sql, (
                    data['url'], data['title'], data['address'],
                    data['price'], data['price_per_m2'],
                    data['old_price'], data['area_total'], data['area_living'], data['area_kitchen'],
                    data['floor_current'], data['floor_total'], data['rooms'], data['year_built'],
                    data['building_type'], data['property_category'], data['property_type'], data['description'],
                    data['seller_type'], data['publication_date'], data['is_active'],
                    data['district'], data['metro_station'], data['metro_time'],
                    now, now, data['cian_id']
                ))
                
                print(f"   üìù –û–±–Ω–æ–≤–ª–µ–Ω–æ –≤ –±–∞–∑–µ")
                
            else:
                insert_sql = f"""
                    INSERT INTO {self.table_name} 
                    (cian_id, url, title, address, price, price_per_m2, old_price,
                     area_total, area_living, area_kitchen, floor_current, floor_total, 
                     rooms, year_built, building_type, property_category, property_type, description,
                     seller_type, publication_date, is_active, district, metro_station,
                     metro_time, created_at, updated_at, last_checked)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, 
                            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """
                
                self.cursor.execute(insert_sql, (
                    data['cian_id'], data['url'], data['title'], data['address'],
                    data['price'], data['price_per_m2'], data['old_price'],
                    data['area_total'], data['area_living'], data['area_kitchen'],
                    data['floor_current'], data['floor_total'], data['rooms'], data['year_built'],
                    data['building_type'], data['property_category'], data['property_type'], data['description'],
                    data['seller_type'], data['publication_date'], data['is_active'],
                    data['district'], data['metro_station'], data['metro_time'],
                    now, now, now
                ))
                
                print(f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –±–∞–∑—É")
            
            self.conn.commit()
            return True
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –±–∞–∑—ã: {e}")
            import traceback
            traceback.print_exc()
            self.conn.rollback()
            return False
    
    def save_to_price_history(self, cian_id, price, timestamp):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Ü–µ–Ω"""
        try:
            insert_sql = """
                INSERT INTO price_history (cian_id, price, date_recorded, change_type)
                VALUES (%s, %s, %s, %s)
            """
            
            self.cursor.execute(insert_sql, (cian_id, price, timestamp, 'update'))
        except:
            pass
    
    def save_to_file(self, data):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ —Ñ–∞–π–ª"""
        try:
            filename = f"cian_offers_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"\nüíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {filename}")
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ —Ñ–∞–π–ª: {e}")
            return False
    
    def show_stats(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        if not self.conn:
            print("\n‚ùå –ù–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ")
            return
        
        try:
            print("\n" + "="*50)
            print(f"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –¢–ê–ë–õ–ò–¶–´ '{self.table_name}'")
            print("="*50)
            
            self.cursor.execute(f"SELECT COUNT(*) FROM {self.table_name}")
            total = self.cursor.fetchone()[0]
            print(f"–í—Å–µ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {total}")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –¥–æ–º–æ–≤
            self.cursor.execute(f"""
                SELECT building_type, COUNT(*) 
                FROM {self.table_name} 
                WHERE building_type IS NOT NULL AND building_type != ''
                GROUP BY building_type
                ORDER BY COUNT(*) DESC
            """)
            building_types = self.cursor.fetchall()
            print("\nüè† –¢–∏–ø—ã –¥–æ–º–æ–≤ (–Ω–∞–π–¥–µ–Ω–æ/–≤—Å–µ–≥–æ):")
            if building_types:
                found_count = sum(bt[1] for bt in building_types)
                print(f"  –° —Ç–∏–ø–æ–º –¥–æ–º–∞: {found_count} –∏–∑ {total}")
                for bt in building_types:
                    print(f"    {bt[0]}: {bt[1]}")
            else:
                print("  –¢–∏–ø—ã –¥–æ–º–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∏ –≤ –æ–¥–Ω–æ–º –æ–±—ä—è–≤–ª–µ–Ω–∏–∏")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏
            self.cursor.execute(f"""
                SELECT property_category, COUNT(*) 
                FROM {self.table_name} 
                WHERE property_category IS NOT NULL AND property_category != ''
                GROUP BY property_category
                ORDER BY COUNT(*) DESC
            """)
            categories = self.cursor.fetchall()
            print("\nüè¢ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏:")
            if categories:
                for cat in categories:
                    print(f"    {cat[0]}: {cat[1]}")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –º–µ—Ç—Ä–æ
            print("\nüöá –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–µ—Ç—Ä–æ:")
            self.cursor.execute(f"""
                SELECT COUNT(*) FROM {self.table_name} 
                WHERE metro_station IS NOT NULL AND metro_station != ''
            """)
            with_metro = self.cursor.fetchone()[0]
            print(f"  –°–æ —Å—Ç–∞–Ω—Ü–∏–µ–π –º–µ—Ç—Ä–æ: {with_metro} –∏–∑ {total}")
            
            self.cursor.execute(f"""
                SELECT COUNT(*) FROM {self.table_name} 
                WHERE metro_time IS NOT NULL AND metro_time != ''
            """)
            with_metro_time = self.cursor.fetchone()[0]
            print(f"  –° –≤—Ä–µ–º–µ–Ω–µ–º –¥–æ –º–µ—Ç—Ä–æ: {with_metro_time} –∏–∑ {total}")
            
            # –ü—Ä–∏–º–µ—Ä—ã —Å –º–µ—Ç—Ä–æ
            print("\nüìã –ü—Ä–∏–º–µ—Ä—ã –æ–±—ä—è–≤–ª–µ–Ω–∏–π —Å –º–µ—Ç—Ä–æ:")
            self.cursor.execute(f"""
                SELECT cian_id, metro_station, metro_time, building_type, property_category
                FROM {self.table_name} 
                WHERE metro_station IS NOT NULL AND metro_station != ''
                ORDER BY created_at DESC 
                LIMIT 5
            """)
            examples = self.cursor.fetchall()
            for ex in examples:
                metro_info = f"–ú–µ—Ç—Ä–æ: {ex[1]}"
                if ex[2]:
                    metro_info += f" ({ex[2]})"
                building_info = f", –¢–∏–ø –¥–æ–º–∞: {ex[3]}" if ex[3] else ""
                category_info = f", –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {ex[4]}" if ex[4] else ""
                print(f"  ID: {ex[0]}, {metro_info}{building_info}{category_info}")
            
            print("="*50)
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
    
    def run_parsing(self):
        """–ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        urls = [
            "https://spb.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=2&room1=1",
            "https://spb.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=2&room2=1"
        ]
        
        all_data = []
        parsed_count = 0
        
        for url in urls[:1]:
            print(f"\nüåê –ü–∞—Ä—Å–∏–º: {url}")
            
            offers = self.parse_search_page(url)
            
            if not offers:
                print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
                continue
            
            for i, offer in enumerate(offers[:3]):  # –ü–∞—Ä—Å–∏–º —Ç–æ–ª—å–∫–æ 3 –¥–ª—è —Ç–µ—Å—Ç–∞
                print(f"\n[{i+1}/{min(3, len(offers))}]")
                
                data = self.parse_offer(offer)
                
                if data:
                    if self.conn:
                        self.save_to_database(data)
                    
                    all_data.append(data)
                    parsed_count += 1
                
                time.sleep(2)
        
        return all_data, parsed_count
    
    def run(self):
        """–ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞"""
        print("="*60)
        print("–ü–ê–†–°–ï–† –¶–ò–ê–ù –î–õ–Ø –¢–ê–ë–õ–ò–¶–´ cian_offers")
        print("="*60)
        
        if not self.setup_browser():
            return
        
        use_db = input("\n–°–æ—Ö—Ä–∞–Ω—è—Ç—å –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö? (y/n): ").lower() == 'y'
        
        if use_db:
            if not self.setup_database():
                print("\n‚ö†Ô∏è –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
                use_db = False
        
        all_data, parsed_count = self.run_parsing()
        
        if all_data:
            self.save_to_file(all_data)
        
        if use_db:
            self.show_stats()
        
        print(f"\n‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print(f"üìà –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {parsed_count} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
        
        if use_db:
            print("\nüí° –û—Ç–∫—Ä–æ–π—Ç–µ DBeaver –∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:")
            print(f"   SELECT cian_id, building_type, property_category, metro_station, metro_time FROM {self.table_name} ORDER BY created_at DESC;")
        
        print("\n" + "="*60)
    
    def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ"""
        try:
            if self.driver:
                self.driver.quit()
                print("‚úÖ –ë—Ä–∞—É–∑–µ—Ä –∑–∞–∫—Ä—ã—Ç")
        except:
            pass
        
        try:
            if self.cursor:
                self.cursor.close()
            if self.conn:
                self.conn.close()
                print("‚úÖ –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–π –∑–∞–∫—Ä—ã—Ç–æ")
        except:
            pass

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = CianParser()
    
    try:
        parser.run()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {str(e)}")
        import traceback
        traceback.print_exc()
    finally:
        parser.close()
    
    input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤—ã—Ö–æ–¥–∞...")

if __name__ == "__main__":
    try:
        import selenium
        import bs4
    except ImportError:
        print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: pip install selenium beautifulsoup4")
        sys.exit(1)
    
    main()